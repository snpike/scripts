{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import emcee\n",
    "import corner\n",
    "from IPython.display import display, Math\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.modeling import functional_models, fitting\n",
    "\n",
    "import stingray.events as ev\n",
    "import stingray.lightcurve as lc\n",
    "from stingray import io\n",
    "import stingray.powerspectrum as powspec \n",
    "import stingray.crossspectrum as crossspec\n",
    "from hendrics.efsearch import dyn_folding_search, z_n_search, folding_search\n",
    "import stingray.gti as sting_gti\n",
    "import stingray.pulse.pulsar as plsr\n",
    "from stingray import stats\n",
    "\n",
    "\n",
    "sns.set_context('talk')\n",
    "# sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "sys.path.insert(1, '/Users/sean/scripts/helpers')\n",
    "\n",
    "from stingray_plus import *\n",
    "\n",
    "def minimize_remainder(arr, min_div, max_div):\n",
    "    divisors = np.linspace(min_div, max_div, num=100)\n",
    "    remainders = []\n",
    "    for div in divisors:\n",
    "        remainders.append(np.sum(np.mod(arr, div)))\n",
    "        \n",
    "    return divisors[np.argmin(remainders)]\n",
    "\n",
    "def power_law(f, B, gamma):\n",
    "    return B*np.power(f,gamma)\n",
    "\n",
    "def Lorentzian(f, peakf, Q, A):\n",
    "    gamma = peakf/(2.0 * Q)\n",
    "    return (A * np.square(gamma)/(np.pi*gamma*(np.square(f-peakf) + np.square(gamma))))\n",
    "\n",
    "def Lorentzian_C(f, peakf, Q, A, C):\n",
    "    return Lorentzian(f, peakf, Q, A) + C\n",
    "\n",
    "def Lorentzian_power(f, peakf, Q, A, B, gamma):\n",
    "    return Lorentzian(f, peakf, Q, A) + power_law(f, B, gamma)\n",
    "\n",
    "def N_Lorentzians(f, *args):\n",
    "    N = int((len(args)-1)/3)\n",
    "    peaks = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    B, gamma = args[-2:]\n",
    "    model = power_law(f, B, gamma)\n",
    "    for i in range(N):\n",
    "        gamma = peaks[i]/(2.0 * Qs[i])\n",
    "        model = model + (As[i] * np.square(gamma)/(np.pi*gamma*(np.square(f-peaks[i]) + np.square(gamma))))\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def QPO_scan(cross_spec, f_min=1e-4, f_max=2000., f_bin=1000):\n",
    "    f_mask = (cross_spec.freq > f_min) * (cross_spec.freq < f_max)\n",
    "    freq_steps = np.logspace(np.log10(cross_spec.freq[f_mask][0]), np.log10(cross_spec.freq[f_mask][-1]), f_bin + 2)\n",
    "    xdata = cross_spec.freq[f_mask]\n",
    "    ydata = cross_spec.power[f_mask]\n",
    "    sigma = cross_spec.power_err[f_mask]\n",
    "    \n",
    "    pl_popt, pl_pcov = scipy.optimize.curve_fit(power_law, xdata, ydata, sigma = sigma, p0 = [10., -1.0], \\\n",
    "                                                bounds=np.array([(0.0, np.inf), (-np.inf, 0.0)]).T)\n",
    "    print(pl_popt)\n",
    "    chisq0 = np.sum(((ydata - power_law(xdata, *pl_popt)) / sigma) ** 2)\n",
    "    chisq = []\n",
    "    for i in tqdm(range(len(freq_steps[1:-1]))):\n",
    "        f = freq_steps[i+1]\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_power, xdata, ydata, sigma = sigma, p0 = [f, 2.0, 0.1, pl_popt[0], pl_popt[1]], \\\n",
    "                                              bounds=np.array([(f - (f-freq_steps[i])/2., f + (freq_steps[i+2] - f)/2.0), (1.0,np.inf), (0.0,np.inf), (0.0, np.inf), (-np.inf, 0.0)]).T)\n",
    "        chisq.append(np.sum(((ydata - Lorentzian_power(xdata, *popt)) / sigma) ** 2))\n",
    "    dof = len(xdata)-len(popt)\n",
    "    return freq_steps[1:-1], chisq0, np.array(chisq), dof\n",
    "\n",
    "\n",
    "def sim_Poisson_cospectra(lc_len, dt, mean_rate_A, mean_rate_B, n_lc):\n",
    "    # Simulate a number of cross spectra due to Poisson noise.\n",
    "    \n",
    "    cross_spectra = []\n",
    "    lc_times = np.linspace(0.,lc_len, int(np.floor(lc_len/dt)))\n",
    "    \n",
    "    for i in range(n_lc):\n",
    "        sim_lc_counts_A = np.random.poisson(mean_rate_A*dt, size = np.shape(lc_times))\n",
    "        sim_lc_counts_B = np.random.poisson(mean_rate_B*dt, size = np.shape(lc_times))\n",
    "        lcA = lc.Lightcurve(lc_times, sim_lc_counts_A, dt=dt)\n",
    "        lcB = lc.Lightcurve(lc_times, sim_lc_counts_B, dt=dt)\n",
    "        cross = crossspec.Crossspectrum(lcA, lcB, norm='leahy')\n",
    "        cross_spectra.append(cross)\n",
    "    \n",
    "    averaged_cross = cross_spectra[0]\n",
    "\n",
    "    averaged_cross.m = len(cross_spectra)\n",
    "\n",
    "    for i in range(len(cross_spectra))[1:]:\n",
    "        averaged_cross.power += cross_spectra[i].power\n",
    "        averaged_cross.unnorm_power += cross_spectra[i].unnorm_power\n",
    "        averaged_cross.power_err += np.square(cross_spectra[i].power_err)\n",
    "        averaged_cross.nphots1 += cross_spectra[i].nphots1\n",
    "        averaged_cross.nphots2 += cross_spectra[i].nphots2\n",
    "\n",
    "    averaged_cross.power = averaged_cross.power/averaged_cross.m\n",
    "    averaged_cross.unnorm_power = averaged_cross.unnorm_power/averaged_cross.m\n",
    "    averaged_cross.power_err = np.sqrt(averaged_cross.power_err)/averaged_cross.m\n",
    "    averaged_cross.nphots1 = averaged_cross.nphots1/averaged_cross.m\n",
    "    averaged_cross.nphots2 = averaged_cross.nphots2/averaged_cross.m\n",
    "    \n",
    "    return averaged_cross\n",
    "\n",
    "def QPO_sim(Q, A, peakf, lc_len, dt, mean_rate_A, mean_rate_B, n_lc, f_min, f_max, num_trials = 100):\n",
    "    # Simulate many cospectra due to Poisson noise then model with and without a Lorentzian QPO.\n",
    "    # Return the distribution of resulting improvements to the fit.\n",
    "    \n",
    "    delta_chisq = []\n",
    "\n",
    "    for i in tqdm(range(num_trials)):\n",
    "        cross = sim_Poisson_cospectra(lc_len, dt, mean_rate_A, mean_rate_B, n_lc)\n",
    "        f_mask = (cross.freq > f_min) * (cross.freq < f_max)\n",
    "        xdata = cross.freq[f_mask]\n",
    "        ydata = cross.power[f_mask]\n",
    "        sigma = cross.power_err[f_mask]\n",
    "        chisq0 = np.sum(((ydata -np.mean(ydata)) / sigma) ** 2)\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_C, xdata, ydata, sigma = sigma, p0 = [peakf, Q, A, 0.0], \\\n",
    "                                              bounds =np.array([(f_min, f_max), (0.99*Q, 1.01*Q), (0.99*A, 1.01*A), (-np.inf, np.inf)]).T)\n",
    "        chisq = np.sum(((ydata - Lorentzian_C(xdata, *popt)) / sigma) ** 2)\n",
    "        delta_chisq.append(chisq - chisq0)\n",
    "    \n",
    "    return delta_chisq\n",
    "\n",
    "def log_likelihood(theta, f, p, p_err):\n",
    "    # ln(likelihood of data given model)\n",
    "    log_f = theta[-1]\n",
    "    # Model is 2 Lorentzians plus a constant\n",
    "    model = N_Lorentzians(f, p, *(theta[:-1]))\n",
    "    \n",
    "    sigma2 = p_err ** 2 + model ** 2 * np.exp(2 * log_f)\n",
    "    return -0.5 * np.sum((p - model) ** 2 / sigma2 + np.log(sigma2))\n",
    "\n",
    "def log_prior(theta, *mu_sigma):\n",
    "    # ln(likelihood of model). Gaussian priors given by results of least square fit.\n",
    "    # mu_sigma gives the mean and std dev of gaussian prior for each peak frequency, Q, and A.\n",
    "    # It has the form [*peak frequencies mu, *Q mu, *A mu, *peak frequencies sigma, *Q sigma, *A sigma]\n",
    "    # theta should have form [*peak frequencies, *Q, *A, C, log_f]\n",
    "    N = int((len(theta)-2)/3)\n",
    "    log_f = theta[-1]\n",
    "    prior_params = np.array(theta[:-2])\n",
    "    \n",
    "    mu = np.array(mu_sigma[:N*3])\n",
    "    sigma = mu_sigma[N*3:]\n",
    "#     print((N))\n",
    "    \n",
    "    if (not np.sum(prior_params <= 0.0)) and (-10.0 < log_f < 1.0):\n",
    "        return -np.sum(np.square((prior_params-mu)/sigma))/2.0\n",
    "    else:\n",
    "        return -np.inf\n",
    "\n",
    "def log_probability(theta, f, p, p_err, *mu_sigma):\n",
    "    # ln(likelihood of model given data) also the posterior\n",
    "    \n",
    "    lp = log_prior(theta, *mu_sigma)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, f, p, p_err)\n",
    "\n",
    "def fit_peaks(xdata, ydata, sigma, nu_peak):\n",
    "    \n",
    "    popt_arr = []\n",
    "    pcov_arr = []\n",
    "\n",
    "    for i, p in enumerate(nu_peak):\n",
    "        f_bound = None\n",
    "        if len(nu_peak)==1:\n",
    "            f_bound = (np.min(xdata), np.max(xdata))\n",
    "        else:\n",
    "            if i == 0:\n",
    "                f_bound = (np.min(xdata), p + (nu_peak[i+1] - p)/2)\n",
    "            elif i==len(nu_peak)-1:\n",
    "                f_bound = (p + (nu_peak[i-1] - p)/2, np.max(xdata))\n",
    "            else:\n",
    "                f_bound = (p + (nu_peak[i-1] - p)/2, p + (nu_peak[i+1] - p)/2)\n",
    "\n",
    "        par_bounds = np.array([f_bound, (1.0,np.inf), (0, np.inf), (0, np.inf), (-np.inf, 0.0)]).T\n",
    "        p0 = [p, 5.0, 0.1, 0.02, -0.5]\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_power, xdata, ydata, sigma = sigma, p0 = p0, bounds = par_bounds)\n",
    "        popt_arr.append(popt)\n",
    "        pcov_arr.append(pcov)\n",
    "\n",
    "    popt_arr = np.array(popt_arr)\n",
    "    pcov_arr = np.array(pcov_arr)\n",
    "\n",
    "    return popt_arr, pcov_arr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Macbook\n"
     ]
    }
   ],
   "source": [
    "if platform=='linux' or platform=='linux2':\n",
    "    print('Working on SRL server')\n",
    "    root_dir = '/disk/lif2/spike/GRS_1741d9m2853/'\n",
    "elif platform=='darwin':\n",
    "    print('Working on Macbook')\n",
    "    root_dir = '/Volumes/Samsung_1TB/AstroData/GRS_1741d9m2853/'\n",
    "\n",
    "timing_dir = root_dir + 'timing_products/'\n",
    "products_dir = root_dir + 'products/'\n",
    "plot_dir = root_dir + 'figures/'\n",
    "\n",
    "OBSID = '90601317002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(326544755.2406748, 326544795.7752123)]\n",
      "[(326584617.41875273, 326584641.30960333)]\n",
      "[(326544755.2406748, 326544795.7752123), (326584617.41875273, 326584641.30960333)]\n",
      "[(326531992.76089, 326544655.2406748), (326545295.7752123, 326584517.41875273), (326585141.30960333, 326587440.76089)]\n",
      "[[326534755.2406748, 326544755.2406748]]\n",
      "[[326574617.41875273, 326584617.41875273]]\n"
     ]
    }
   ],
   "source": [
    "burst1_gti = list(fits.open(root_dir + 'burst1/' + 'burst1_gti.fits')[1].data)\n",
    "burst2_gti = list(fits.open(root_dir + 'burst2/' + 'burst2_gti.fits')[1].data)\n",
    "\n",
    "burst_gti = [*burst1_gti, *burst2_gti]\n",
    "\n",
    "persistent_gti = list(fits.open(root_dir + 'persistent_gti.fits')[1].data)\n",
    "\n",
    "pre_burst1_gti = [[burst1_gti[0][0] - 10000, burst1_gti[0][0]]]\n",
    "pre_burst2_gti = [[burst2_gti[0][0] - 10000, burst2_gti[0][0]]]\n",
    "\n",
    "print(burst1_gti)\n",
    "print(burst2_gti)\n",
    "print(burst_gti)\n",
    "print(persistent_gti)\n",
    "print(pre_burst1_gti)\n",
    "print(pre_burst2_gti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:375: RuntimeWarning: underflow encountered in exp\n",
      "  (c * ydiff ** 2)))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:399: RuntimeWarning: underflow encountered in exp\n",
      "  (c * ydiff2)))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:409: RuntimeWarning: underflow encountered in true_divide\n",
      "  dg_dA = g / amplitude\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:410: RuntimeWarning: underflow encountered in multiply\n",
      "  dg_dx_mean = g * ((2. * a * xdiff) + (b * ydiff))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:411: RuntimeWarning: underflow encountered in multiply\n",
      "  dg_dy_mean = g * ((b * xdiff) + (2. * c * ydiff))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:414: RuntimeWarning: underflow encountered in multiply\n",
      "  dc_dx_stddev * ydiff2))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:417: RuntimeWarning: underflow encountered in multiply\n",
      "  dc_dy_stddev * ydiff2))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:375: RuntimeWarning: underflow encountered in multiply\n",
      "  (c * ydiff ** 2)))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:399: RuntimeWarning: underflow encountered in multiply\n",
      "  (c * ydiff2)))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/functional_models.py:420: RuntimeWarning: underflow encountered in multiply\n",
      "  dc_dtheta * ydiff2))\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/astropy/modeling/fitting.py:897: RuntimeWarning: underflow encountered in square\n",
      "  sum_sqrs = np.sum(self.objective_function(fitparams, *farg)**2)\n",
      "/Users/sean/scripts/helpers/stingray_plus.py:70: RuntimeWarning: underflow encountered in true_divide\n",
      "  self.xy_weights = g(self.x, self.y)/g.amplitude\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.11557975e-001, 1.33306525e-197, 1.67478870e-003, ...,\n",
       "       7.00905624e-009, 4.81768486e-012, 2.68510653e-006])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI_min = 35     # 3.0 keV\n",
    "# PI_min = 260     # 12.0 keV\n",
    "PI_max = 960   # 40.0 keV\n",
    "# PI_max = 1909   # 78.0 keV\n",
    "events = extract_events(timing_dir + 'nu' + OBSID + 'A01_cl_barycorr.evt', \\\n",
    "            timing_dir + 'nu' + OBSID + 'B01_cl_barycorr.evt')\n",
    "\n",
    "centroid_A = [535.45075,442.58818]\n",
    "centroid_B = [529.34253,440.82937]\n",
    "extraction_radius = 40.681706\n",
    "\n",
    "events[0].set_xy_weights(centroid=centroid_A)\n",
    "events[1].set_xy_weights(centroid=centroid_B)\n",
    "# joined_events = events[0].join(events[1])\n",
    "# print(events[0].time)\n",
    "\n",
    "# plt.ion()\n",
    "\n",
    "# curveA = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_sr.lc'), nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_bk.lc'))\n",
    "# curveB = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_sr.lc'), nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_bk.lc'))\n",
    "# curve_total = sum_lc(curveA, curveB)\n",
    "# # curve_10s = curve_total.rebin(dt_new=10)\n",
    "\n",
    "# t_start = np.min(curve_total.time)\n",
    "\n",
    "# plt.figure(figsize = (9,6))\n",
    "# plt.errorbar(curve_total.time-t_start, curve_total.countrate, xerr=curve_total.dt/2., yerr=curve_total.countrate_err, fmt='none', lw = 0.5)\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('NuSTAR count rate')\n",
    "# plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent Cospectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530.3030303030303\n"
     ]
    }
   ],
   "source": [
    "gti_lens = np.array([(g[1]-g[0]) for g in sting_gti.cross_two_gtis(events[0].gti, persistent_gti)])\n",
    "len_mask = gti_lens > 500.\n",
    "split_time = minimize_remainder(gti_lens[len_mask], 500,1500)\n",
    "print(split_time)\n",
    "ms_bin = 0.0001\n",
    "f_res = 0.05\n",
    "\n",
    "# print(events[0].split_by_time(bintime=split_time))\n",
    "curves_A = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius) for x in events[0].split_by_time(bintime=split_time, gti=persistent_gti)]\n",
    "# curves_B = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius) for x in events[1].split_by_time(bintime=split_time, gti=persistent_gti)]\n",
    "\n",
    "n_curves = len(curves_A)\n",
    "\n",
    "curves_A=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:18<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "cross_spectra = []\n",
    "for i in tqdm(range(n_curves)):\n",
    "    cross_file = open(timing_dir + 'analysis_products/persistent_cross_spectrum_' + str(int(split_time)) + 's_segment' + str(i) + '.txt', 'rb')\n",
    "    cross = pickle.load(cross_file)\n",
    "    cross_file.close()\n",
    "    cross_spectra.append(cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# averaged_cross = cross_spectra[0]\n",
    "\n",
    "# averaged_cross.m = len(cross_spectra)\n",
    "\n",
    "# for i in range(len(cross_spectra))[1:]:\n",
    "#     averaged_cross.power += cross_spectra[i].power\n",
    "#     averaged_cross.unnorm_power += cross_spectra[i].unnorm_power\n",
    "#     averaged_cross.power_err += np.square(cross_spectra[i].power_err)\n",
    "#     averaged_cross.nphots1 += cross_spectra[i].nphots1\n",
    "#     averaged_cross.nphots2 += cross_spectra[i].nphots2\n",
    "    \n",
    "# averaged_cross.power = averaged_cross.power/averaged_cross.m\n",
    "# averaged_cross.unnorm_power = averaged_cross.unnorm_power/averaged_cross.m\n",
    "# averaged_cross.power_err = np.sqrt(averaged_cross.power_err)/averaged_cross.m\n",
    "# averaged_cross.nphots1 = averaged_cross.nphots1/averaged_cross.m\n",
    "# averaged_cross.nphots2 = averaged_cross.nphots2/averaged_cross.m\n",
    "\n",
    "# cross_file = open(timing_dir + 'analysis_products/' + 'persistent_cross_spectrum_average.txt', 'wb')\n",
    "# pickle.dump(averaged_cross, cross_file)\n",
    "# cross_file.close()\n",
    "\n",
    "cross_file = open(timing_dir + 'analysis_products/' + 'persistent_cross_spectrum_average.txt', 'rb')\n",
    "averaged_cross = pickle.load(cross_file)\n",
    "cross_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan for QPOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00344522 -1.11135956]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [34:52<00:00,  4.18s/it] \n"
     ]
    }
   ],
   "source": [
    "f_min = np.min(averaged_cross.freq)\n",
    "f_max = np.min([2000., (np.max(averaged_cross.freq))])\n",
    "freqs, chisq0, chisq, dof = QPO_scan(averaged_cross, f_min=f_min, f_max=f_max, f_bin = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981585614537357\n",
      "1058645.9721192706\n"
     ]
    }
   ],
   "source": [
    "print(chisq0/dof)\n",
    "print(chisq0)\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(freqs, (chisq - chisq0))\n",
    "plt.xscale('log')\n",
    "plt.ylabel(r'$\\Delta\\chi^{2}$')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'persistent_QPO_scan.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.51408773e-01  3.21151101e+00  2.90147567e-03  3.25475242e-03\n",
      " -1.12223000e+00]\n",
      "[ 7.99117821e+00  8.66153205e+00  2.87714580e-02  3.31034986e-03\n",
      " -1.11915258e+00]\n",
      "[ 4.69729297e+01  6.13757239e+00  3.52055470e-02  3.41275890e-03\n",
      " -1.11321496e+00]\n",
      "[ 1.16009183e+03  1.99472755e+01  6.76654644e-02  3.44201168e-03\n",
      " -1.11154439e+00]\n",
      "0.34343995661903925\n",
      "1.4443118130598473\n",
      "0.6144929453429928\n",
      "0.4289793305126663\n"
     ]
    }
   ],
   "source": [
    "peaks, _ = scipy.signal.find_peaks(-(chisq - chisq0), height = 8.0)\n",
    "QPO_candidates = []\n",
    "f_mask = (averaged_cross.freq > f_min) * (averaged_cross.freq < f_max) \n",
    "xdata = averaged_cross.freq[f_mask]\n",
    "ydata = averaged_cross.power[f_mask]\n",
    "sigma = averaged_cross.power_err[f_mask]\n",
    "\n",
    "popt_arr, pcov_arr = fit_peaks(xdata, ydata, sigma, freqs[peaks])\n",
    "\n",
    "sigma_arr = []\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i])\n",
    "#     print(np.sqrt(np.diag(pcov_arr[i])))\n",
    "    sigma_arr.append(np.sqrt(np.diag(pcov_arr[i])))\n",
    "sigma_arr = np.array(sigma_arr)\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i][2]/sigma_arr[i][2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "f_res = 0.05\n",
    "plt.figure(figsize=(9,6))\n",
    "averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "temp_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power.real, xerr=temp_err, yerr=averaged_cross_log.power_err, fmt='none', lw=0.5)\n",
    "plt.plot(averaged_cross_log.freq, Lorentzian_power(averaged_cross_log.freq, *(popt_arr[0])), color='red')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-4,1.))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Leahy Power')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(plot_dir + 'persistent_averaged_cross_spectrum_' + str(int(split_time)) + 's_QPO_fit.pdf')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burst Cospectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "[3.26544755e+08 3.26544755e+08 3.26544755e+08 ... 3.26544765e+08\n",
      " 3.26544765e+08 3.26544765e+08]\n"
     ]
    }
   ],
   "source": [
    "gti_lens = np.array([(g[1]-g[0]) for g in sting_gti.cross_two_gtis(events[0].gti, burst_gti)])\n",
    "split_time = minimize_remainder(gti_lens, 10.,1000.)\n",
    "print(split_time)\n",
    "ms_bin = 0.0001\n",
    "f_res = 0.05\n",
    "\n",
    "# print(events[0].split_by_time(bintime=split_time))\n",
    "curves_A = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius) for x in events[0].split_by_time(bintime=split_time, gti=burst_gti)]\n",
    "curves_B = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius) for x in events[1].split_by_time(bintime=split_time, gti=burst_gti)]\n",
    "\n",
    "print(curves_A[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 31.54it/s]\n"
     ]
    }
   ],
   "source": [
    "cross_spectra = []\n",
    "for i in tqdm(range(len(curves_A))):\n",
    "    cross_file = open(timing_dir + 'analysis_products/burst_cross_spectrum_' + str(int(split_time)) + 's_segment' + str(i) + '.txt', 'rb')\n",
    "    cross = pickle.load(cross_file)\n",
    "    cross_file.close()\n",
    "    cross_spectra.append(cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "averaged_cross = cross_spectra[0]\n",
    "\n",
    "averaged_cross.m = len(cross_spectra)\n",
    "\n",
    "for i in range(len(cross_spectra))[1:]:\n",
    "    averaged_cross.power += cross_spectra[i].power\n",
    "    averaged_cross.unnorm_power += cross_spectra[i].unnorm_power\n",
    "    averaged_cross.power_err += np.square(cross_spectra[i].power_err)\n",
    "    averaged_cross.nphots1 += cross_spectra[i].nphots1\n",
    "    averaged_cross.nphots2 += cross_spectra[i].nphots2\n",
    "    \n",
    "averaged_cross.power = averaged_cross.power/averaged_cross.m\n",
    "averaged_cross.unnorm_power = averaged_cross.unnorm_power/averaged_cross.m\n",
    "averaged_cross.power_err = np.sqrt(averaged_cross.power_err)/averaged_cross.m\n",
    "averaged_cross.nphots1 = averaged_cross.nphots1/averaged_cross.m\n",
    "averaged_cross.nphots2 = averaged_cross.nphots2/averaged_cross.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.024428886330163685\n",
      "0.09870024807360071\n"
     ]
    }
   ],
   "source": [
    "tmp_mask = (averaged_cross.freq <= 590) * (averaged_cross.freq >= 588)\n",
    "\n",
    "# rms = crossspec.normalize_crossspectrum(averaged_cross.unnorm_power, 10, )\n",
    "print(np.sum(averaged_cross.power[tmp_mask])*10/np.sqrt(np.exp(np.log(averaged_cross.nphots1) + np.log(averaged_cross.nphots2))))\n",
    "print(np.sqrt(np.sum(np.square(averaged_cross.power_err[tmp_mask])))*2.6*10/np.sqrt(np.exp(np.log(averaged_cross.nphots1) + np.log(averaged_cross.nphots2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan for QPOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:00<00:29, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26232159 -2.12672135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:46<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "source": [
    "f_min = np.min(averaged_cross.freq)\n",
    "f_max = np.min([2000., (np.max(averaged_cross.freq))])\n",
    "freqs, chisq0, chisq, dof = QPO_scan(averaged_cross, f_min=f_min, f_max=f_max, f_bin = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0192679782822567\n"
     ]
    }
   ],
   "source": [
    "print(chisq0/dof)\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(freqs, (chisq - chisq0))\n",
    "plt.xscale('log')\n",
    "plt.ylabel(r'$\\Delta\\chi^{2}$')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'burst_QPO_scan.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.18703532e+03  1.29631149e+02  2.21004771e+00  2.62263425e-01\n",
      " -2.12687100e+00]\n",
      "[ 1.85097360e+03  1.61683559e+02  3.94975355e+00  2.62263748e-01\n",
      " -2.12687020e+00]\n",
      "1.6209724425999592\n",
      "2.5913252335692993\n"
     ]
    }
   ],
   "source": [
    "peaks, _ = scipy.signal.find_peaks(-(chisq - chisq0), height = 10.0)\n",
    "QPO_candidates = []\n",
    "f_mask = (averaged_cross.freq > f_min) * (averaged_cross.freq < f_max) \n",
    "xdata = averaged_cross.freq[f_mask]\n",
    "ydata = averaged_cross.power[f_mask]\n",
    "sigma = averaged_cross.power_err[f_mask]\n",
    "\n",
    "popt_arr, pcov_arr = fit_peaks(xdata, ydata, sigma, freqs[peaks])\n",
    "\n",
    "sigma_arr = []\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i])\n",
    "    print(np.sqrt(np.diag(pcov_arr[i])))\n",
    "    sigma_arr.append(np.sqrt(np.diag(pcov_arr[i])))\n",
    "sigma_arr = np.array(sigma_arr)\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i][2]/sigma_arr[i][2])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "f_res = 0.05\n",
    "plt.figure(figsize=(9,6))\n",
    "averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "temp_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power.real, xerr=temp_err, yerr=averaged_cross_log.power_err, fmt='none', lw=0.5)\n",
    "plt.plot(averaged_cross_log.freq, Lorentzian_power(averaged_cross_log.freq, *(popt_arr[1])), color='red')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,100.))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Leahy Power')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(plot_dir + 'burst_averaged_cross_spectrum_' + str(int(split_time)) + 's_QPO_fit.pdf')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Burst 1 Cospectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515.1515151515151\n",
      "[3.26534755e+08 3.26534755e+08 3.26534755e+08 ... 3.26535270e+08\n",
      " 3.26535270e+08 3.26535270e+08]\n"
     ]
    }
   ],
   "source": [
    "gti_lens = np.array([(g[1]-g[0]) for g in sting_gti.cross_two_gtis(events[0].gti, pre_burst1_gti)])\n",
    "split_time = minimize_remainder(gti_lens, 500.,2000.)\n",
    "print(split_time)\n",
    "ms_bin = 0.0001\n",
    "f_res = 0.05\n",
    "\n",
    "# print(events[0].split_by_time(bintime=split_time))\n",
    "curves_A = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius) for x in events[0].split_by_time(bintime=split_time, gti=pre_burst1_gti)]\n",
    "curves_B = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius) for x in events[1].split_by_time(bintime=split_time, gti=pre_burst1_gti)]\n",
    "\n",
    "print(curves_A[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "cross_spectra = []\n",
    "for i in tqdm(range(len(curves_A))):\n",
    "    cross_file = open(timing_dir + 'analysis_products/preburst1_cross_spectrum_' + str(int(split_time)) + 's_segment' + str(i) + '.txt', 'rb')\n",
    "    cross = pickle.load(cross_file)\n",
    "    cross_file.close()\n",
    "    cross_spectra.append(cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "averaged_cross = cross_spectra[0]\n",
    "\n",
    "averaged_cross.m = len(cross_spectra)\n",
    "\n",
    "for i in range(len(cross_spectra))[1:]:\n",
    "    averaged_cross.power += cross_spectra[i].power\n",
    "    averaged_cross.unnorm_power += cross_spectra[i].unnorm_power\n",
    "    averaged_cross.power_err += np.square(cross_spectra[i].power_err)\n",
    "    averaged_cross.nphots1 += cross_spectra[i].nphots1\n",
    "    averaged_cross.nphots2 += cross_spectra[i].nphots2\n",
    "    \n",
    "averaged_cross.power = averaged_cross.power/averaged_cross.m\n",
    "averaged_cross.unnorm_power = averaged_cross.unnorm_power/averaged_cross.m\n",
    "averaged_cross.power_err = np.sqrt(averaged_cross.power_err)/averaged_cross.m\n",
    "averaged_cross.nphots1 = averaged_cross.nphots1/averaged_cross.m\n",
    "averaged_cross.nphots2 = averaged_cross.nphots2/averaged_cross.m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan for QPOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.09805232e-08 -1.60319817e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 397/500 [27:50<06:59,  4.07s/it]/Users/sean/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: underflow encountered in power\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: underflow encountered in multiply\n",
      " 83%|████████▎ | 416/500 [28:36<03:06,  2.22s/it]/Users/sean/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in power\n",
      "100%|██████████| 500/500 [32:25<00:00,  3.89s/it]\n"
     ]
    }
   ],
   "source": [
    "f_min = np.min(averaged_cross.freq)\n",
    "f_max = np.min([2000., (np.max(averaged_cross.freq))])\n",
    "freqs, chisq0, chisq, dof = QPO_scan(averaged_cross, f_min=f_min, f_max=f_max, f_bin = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.027641820648177\n"
     ]
    }
   ],
   "source": [
    "print(chisq0/dof)\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(freqs, (chisq - chisq0))\n",
    "plt.xscale('log')\n",
    "plt.ylabel(r'$\\Delta\\chi^{2}$')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'preburst1_QPO_scan.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.44711285e+01  6.37231953e+00  4.99375301e-02  6.51663862e-07\n",
      " -6.56217282e-01]\n",
      "[1.77887421e+00 1.45579839e+01 8.28404272e-02 7.13247824e-03\n",
      " 2.77195424e+03]\n",
      "0.6028159417161971\n"
     ]
    }
   ],
   "source": [
    "peaks, _ = scipy.signal.find_peaks(-(chisq - chisq0), height = 8.0)\n",
    "QPO_candidates = []\n",
    "f_mask = (averaged_cross.freq > f_min) * (averaged_cross.freq < f_max) \n",
    "xdata = averaged_cross.freq[f_mask]\n",
    "ydata = averaged_cross.power[f_mask]\n",
    "sigma = averaged_cross.power_err[f_mask]\n",
    "\n",
    "popt_arr, pcov_arr = fit_peaks(xdata, ydata, sigma, freqs[peaks])\n",
    "\n",
    "sigma_arr = []\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i])\n",
    "    print(np.sqrt(np.diag(pcov_arr[i])))\n",
    "    sigma_arr.append(np.sqrt(np.diag(pcov_arr[i])))\n",
    "sigma_arr = np.array(sigma_arr)\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i][2]/sigma_arr[i][2])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "f_res = 0.05\n",
    "plt.figure(figsize=(9,6))\n",
    "averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "temp_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power.real, xerr=temp_err, yerr=averaged_cross_log.power_err, fmt='none', lw=0.5)\n",
    "plt.plot(averaged_cross_log.freq, Lorentzian_power(averaged_cross_log.freq, *(popt_arr[1])), color='red')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,100.))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Leahy Power')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(plot_dir + 'preburst1_averaged_cross_spectrum_' + str(int(split_time)) + 's_QPO_fit.pdf')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Burst 2 Cospectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545.4545454545455\n",
      "[3.26574617e+08 3.26574617e+08 3.26574617e+08 ... 3.26575163e+08\n",
      " 3.26575163e+08 3.26575163e+08]\n"
     ]
    }
   ],
   "source": [
    "gti_lens = np.array([(g[1]-g[0]) for g in sting_gti.cross_two_gtis(events[0].gti, pre_burst2_gti)])\n",
    "split_time = minimize_remainder(gti_lens, 500.,2000.)\n",
    "print(split_time)\n",
    "ms_bin = 0.0001\n",
    "f_res = 0.05\n",
    "\n",
    "# print(events[0].split_by_time(bintime=split_time))\n",
    "curves_A = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius) for x in events[0].split_by_time(bintime=split_time, gti=pre_burst2_gti)]\n",
    "curves_B = [x.to_lc(dt = ms_bin, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius) for x in events[1].split_by_time(bintime=split_time, gti=pre_burst2_gti)]\n",
    "\n",
    "print(curves_A[0].time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:11<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "cross_spectra = []\n",
    "for i in tqdm(range(len(curves_A))):\n",
    "    cross_file = open(timing_dir + 'analysis_products/preburst2_cross_spectrum_' + str(int(split_time)) + 's_segment' + str(i) + '.txt', 'rb')\n",
    "    cross = pickle.load(cross_file)\n",
    "    cross_file.close()\n",
    "    cross_spectra.append(cross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "averaged_cross = cross_spectra[0]\n",
    "\n",
    "averaged_cross.m = len(cross_spectra)\n",
    "\n",
    "for i in range(len(cross_spectra))[1:]:\n",
    "    averaged_cross.power += cross_spectra[i].power\n",
    "    averaged_cross.unnorm_power += cross_spectra[i].unnorm_power\n",
    "    averaged_cross.power_err += np.square(cross_spectra[i].power_err)\n",
    "    averaged_cross.nphots1 += cross_spectra[i].nphots1\n",
    "    averaged_cross.nphots2 += cross_spectra[i].nphots2\n",
    "    \n",
    "averaged_cross.power = averaged_cross.power/averaged_cross.m\n",
    "averaged_cross.unnorm_power = averaged_cross.unnorm_power/averaged_cross.m\n",
    "averaged_cross.power_err = np.sqrt(averaged_cross.power_err)/averaged_cross.m\n",
    "averaged_cross.nphots1 = averaged_cross.nphots1/averaged_cross.m\n",
    "averaged_cross.nphots2 = averaged_cross.nphots2/averaged_cross.m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan for QPOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00573029 -1.14601813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [41:32<00:00,  4.99s/it]   \n"
     ]
    }
   ],
   "source": [
    "f_min = np.min(averaged_cross.freq)\n",
    "f_max = np.min([2000., (np.max(averaged_cross.freq))])\n",
    "freqs, chisq0, chisq, dof = QPO_scan(averaged_cross, f_min=f_min, f_max=f_max, f_bin = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.030140714818998\n"
     ]
    }
   ],
   "source": [
    "print(chisq0/dof)\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(freqs, (chisq - chisq0))\n",
    "plt.xscale('log')\n",
    "plt.ylabel(r'$\\Delta\\chi^{2}$')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'preburst2_QPO_scan.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.73733392e-02  1.35002956e+02  5.50849671e-02  1.42817803e-03\n",
      " -1.40090608e+00]\n",
      "[1.74857166e-04 3.93590009e+04 1.58998664e+01 1.81160661e-03\n",
      " 2.35515970e-01]\n",
      "[ 7.87857342e+01  7.18209095e+00  1.31618821e-01  5.61321094e-03\n",
      " -1.15009153e+00]\n",
      "[7.37865805e+00 1.36870264e+01 1.77158553e-01 3.68243051e-03\n",
      " 1.27989412e-01]\n",
      "[ 3.09919389e+02  8.45994250e+01  2.61290439e-01  5.65406621e-03\n",
      " -1.14868227e+00]\n",
      "[7.17291272e-01 4.68523295e+01 1.02322029e-01 3.69850717e-03\n",
      " 1.27652857e-01]\n",
      "0.003464492443763883\n",
      "0.7429436432019411\n",
      "2.553608855575088\n"
     ]
    }
   ],
   "source": [
    "peaks, _ = scipy.signal.find_peaks(-(chisq - chisq0), height = 10.0)\n",
    "QPO_candidates = []\n",
    "f_mask = (averaged_cross.freq > f_min) * (averaged_cross.freq < f_max) \n",
    "xdata = averaged_cross.freq[f_mask]\n",
    "ydata = averaged_cross.power[f_mask]\n",
    "sigma = averaged_cross.power_err[f_mask]\n",
    "\n",
    "popt_arr, pcov_arr = fit_peaks(xdata, ydata, sigma, freqs[peaks])\n",
    "\n",
    "sigma_arr = []\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i])\n",
    "    print(np.sqrt(np.diag(pcov_arr[i])))\n",
    "    sigma_arr.append(np.sqrt(np.diag(pcov_arr[i])))\n",
    "sigma_arr = np.array(sigma_arr)\n",
    "\n",
    "for i in range(len(popt_arr)):\n",
    "    print(popt_arr[i][2]/sigma_arr[i][2])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "f_res = 0.05\n",
    "plt.figure(figsize=(9,6))\n",
    "averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "temp_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power.real, xerr=temp_err, yerr=averaged_cross_log.power_err, fmt='none', lw=0.5)\n",
    "plt.plot(averaged_cross_log.freq, Lorentzian_power(averaged_cross_log.freq, *(popt_arr[2])), color='red')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,100.))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Leahy Power')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(plot_dir + 'preburst2_averaged_cross_spectrum_' + str(int(split_time)) + 's_QPO_fit.pdf')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "593px",
    "left": "889px",
    "right": "20px",
    "top": "315px",
    "width": "315px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
