{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: DistributionNotFound error occurred in entry point sherpafitter. [astropy.modeling.fitting]\n",
      "WARNING:root:Warning! NetCDF is not available. Using pickle format.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import emcee\n",
    "import corner\n",
    "from IPython.display import display, Math\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.modeling import functional_models, fitting\n",
    "from astropy.timeseries import LombScargle\n",
    "\n",
    "import stingray.events as ev\n",
    "import stingray.lightcurve as lc\n",
    "from stingray import io\n",
    "import stingray.powerspectrum as powspec \n",
    "import stingray.crossspectrum as crossspec\n",
    "from hendrics.efsearch import dyn_folding_search, z_n_search, folding_search\n",
    "import stingray.gti as sting_gti\n",
    "import stingray.pulse.pulsar as plsr\n",
    "from stingray import stats\n",
    "\n",
    "\n",
    "sns.set_context('talk')\n",
    "# sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "sys.path.insert(1, '/Users/sean/scripts/helpers')\n",
    "\n",
    "from stingray_plus import *\n",
    "\n",
    "def minimize_remainder(arr, min_div, max_div):\n",
    "    divisors = np.linspace(min_div, max_div, num=100)\n",
    "    remainders = []\n",
    "    for div in divisors:\n",
    "        remainders.append(np.sum(np.mod(arr, div)))\n",
    "        \n",
    "    return divisors[np.argmin(remainders)]\n",
    "\n",
    "def power_law(f, B, gamma):\n",
    "    return B*np.power(f,gamma)\n",
    "\n",
    "def Lorentzian(f, peakf, Q, A):\n",
    "    # gamma = HWHM\n",
    "    # peakf = centroid frequency\n",
    "    gamma = peakf/(2.0 * Q)\n",
    "    return (A * np.square(gamma)/(np.pi*gamma*(np.square(f-peakf) + np.square(gamma))))\n",
    "\n",
    "def zero_center_Lorentzian(f, gamma, A):\n",
    "    # gamma = HWHM\n",
    "    # peakf = centroid frequency\n",
    "    return (A * np.square(gamma)/(np.pi*gamma*(np.square(f) + np.square(gamma))))\n",
    "\n",
    "def Lorentzian_C(f, peakf, Q, A, C):\n",
    "    return Lorentzian(f, peakf, Q, A) + C\n",
    "\n",
    "def Lorentzian_power(f, peakf, Q, A, B, gamma):\n",
    "    return Lorentzian(f, peakf, Q, A) + power_law(f, B, gamma)\n",
    "\n",
    "def N_Lorentzian(f, *args):\n",
    "    N = int(len(args)/3)\n",
    "    peak_nu = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    model = np.zeros(np.shape(f))\n",
    "    for i in range(N):\n",
    "        model = model + Lorentzian(f, peak_nu[i], Qs[i], As[i])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def N_Lorentzian_C(f, *args):\n",
    "    N = int((len(args)-1)/3)\n",
    "    peak_nu = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    C = args[-1]\n",
    "    model = C * np.ones(np.shape(f))\n",
    "    for i in range(N):\n",
    "        model = model + Lorentzian(f, peak_nu[i], Qs[i], As[i])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def N_Lorentzian_power(f, *args):\n",
    "    N = int((len(args)-2)/3)\n",
    "    peak_nu = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    B, alpha = args[-2:]\n",
    "    model = power_law(f, B, alpha)\n",
    "    for i in range(N):\n",
    "        gamma = peak_nu[i]/(2.0 * Qs[i])\n",
    "        model = model + (As[i] * np.square(gamma)/(np.pi*gamma*(np.square(f-peak_nu[i]) + np.square(gamma))))\n",
    "        \n",
    "    return model\n",
    "\n",
    "def QPO_scan(cross_spec, f_min=1e-4, f_max=2000., f_bin=1000, n_lorentz = 1):\n",
    "    f_mask = (cross_spec.freq > f_min) * (cross_spec.freq < f_max)\n",
    "    freq_steps = np.logspace(np.log10(cross_spec.freq[f_mask][0]), np.log10(cross_spec.freq[f_mask][-1]), f_bin + 2)\n",
    "    xdata = cross_spec.freq[f_mask]\n",
    "    ydata = cross_spec.power[f_mask]\n",
    "    sigma = cross_spec.power_err[f_mask]\n",
    "    \n",
    "    pl_popt, pl_pcov = scipy.optimize.curve_fit(power_law, xdata, ydata, sigma = sigma, p0 = [10., -1.0], \\\n",
    "                                                bounds=np.array([(0.0, np.inf), (-np.inf, 0.0)]).T)\n",
    "    print(pl_popt)\n",
    "    chisq0 = np.sum(((ydata - power_law(xdata, *pl_popt)) / sigma) ** 2)\n",
    "    chisq = []\n",
    "    for i in tqdm(range(len(freq_steps[1:-1]))):\n",
    "        f = freq_steps[i+1]\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_power, xdata, ydata, sigma = sigma, p0 = [f, 2.0, 0.1, pl_popt[0], pl_popt[1]], \\\n",
    "                                              bounds=np.array([(f - (f-freq_steps[i])/2., f + (freq_steps[i+2] - f)/2.0), (1.0,np.inf), (0.0,np.inf), (0.0, np.inf), (-np.inf, 0.0)]).T)\n",
    "        chisq.append(np.sum(((ydata - Lorentzian_power(xdata, *popt)) / sigma) ** 2))\n",
    "    dof = len(xdata)-len(popt)\n",
    "    return freq_steps[1:-1], chisq0, np.array(chisq), dof\n",
    "\n",
    "\n",
    "\n",
    "def fit_peaks(xdata, ydata, sigma, nu_peak):\n",
    "    \n",
    "    popt_arr = []\n",
    "    pcov_arr = []\n",
    "\n",
    "    for i, p in enumerate(nu_peak):\n",
    "        f_bound = None\n",
    "        if len(nu_peak)==1:\n",
    "            f_bound = (np.min(xdata), np.max(xdata))\n",
    "        else:\n",
    "            if i == 0:\n",
    "                f_bound = (np.min(xdata), p + (nu_peak[i+1] - p)/2)\n",
    "            elif i==len(nu_peak)-1:\n",
    "                f_bound = (p + (nu_peak[i-1] - p)/2, np.max(xdata))\n",
    "            else:\n",
    "                f_bound = (p + (nu_peak[i-1] - p)/2, p + (nu_peak[i+1] - p)/2)\n",
    "\n",
    "        par_bounds = np.array([f_bound, (1.0,np.inf), (0, np.inf), (0, np.inf), (-np.inf, 0.0)]).T\n",
    "        p0 = [p, 5.0, 0.1, 0.02, -0.5]\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_power, xdata, ydata, sigma = sigma, p0 = p0, bounds = par_bounds)\n",
    "        popt_arr.append(popt)\n",
    "        pcov_arr.append(pcov)\n",
    "\n",
    "    popt_arr = np.array(popt_arr)\n",
    "    pcov_arr = np.array(pcov_arr)\n",
    "\n",
    "    return popt_arr, pcov_arr\n",
    "\n",
    "def get_rms(events, centroids, radius, PI_min=35, PI_max=1210, nu_min=1e-4, nu_max=100., split_time=512, bin_time = 1/1024, plot = False):\n",
    "    \n",
    "    curve_A = events[0].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroids[0], radius = radius)\n",
    "    curve_B = events[1].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroids[1], radius = radius)\n",
    "    \n",
    "    average_CPDS = crossspec.AveragedCrossspectrum(curve_A, curve_B, segment_size=split_time, norm = 'frac')\n",
    "    \n",
    "    if plot:\n",
    "        f_res = 0.1\n",
    "        plt.figure(figsize=(9,6))\n",
    "        averaged_cross_log = average_CPDS.rebin_log(f=f_res)\n",
    "        averaged_cross_log_err = average_CPDS.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "        plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power*averaged_cross_log.freq, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err*averaged_cross_log.freq, fmt='none', lw=0.5)\n",
    "        plt.xscale('log')\n",
    "        plt.ylim((1e-4,5*np.max(averaged_cross_log.power.real)))\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Leahy Power')\n",
    "        plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "#         plt.savefig(plot_dir + 'averaged_cross_spectrum_' + str(int(split_time)) + 's.pdf')\n",
    "        plt.close()\n",
    "    \n",
    "    rms_square = np.sum(average_CPDS.power[(average_CPDS.freq > nu_min) * (average_CPDS.freq < nu_max)])*average_CPDS.df\n",
    "    rms_square_err = np.sqrt(np.sum(np.square(average_CPDS.power_err[(average_CPDS.freq > nu_min) * (average_CPDS.freq < nu_max)])))*average_CPDS.df\n",
    "    \n",
    "    if rms_square < 0.0:\n",
    "        uplim = True\n",
    "        rms = np.sqrt(rms_square + 2.6*rms_square_err)\n",
    "    else:\n",
    "        uplim = False\n",
    "        rms = np.sqrt(rms_square)\n",
    "        \n",
    "    rms_err = np.sqrt(np.sum(np.square(average_CPDS.power_err[(average_CPDS.freq > nu_min) * (average_CPDS.freq < nu_max)])))*average_CPDS.df/(2*rms)\n",
    "\n",
    "    return rms, rms_err, uplim\n",
    "\n",
    "def model_continuum_noise_zero_center(cpds, plot=True, plot_dir='/Users/sean/Desktop/', f_res = 0.5):\n",
    "\n",
    "    chisq0 = np.sum(((cpds.power-np.mean(cpds.power))/ cpds.power_err) ** 2)\n",
    "\n",
    "    popt, pcov = scipy.optimize.curve_fit(zero_center_Lorentzian, cpds.freq, cpds.power, sigma = cpds.power_err, \\\n",
    "                                          p0 = [0.1, 10.], bounds= [[0.0,0.0], [np.inf, np.inf]])\n",
    "    chisq = np.sum(((cpds.power - zero_center_Lorentzian(cpds.freq, *popt)) / cpds.power_err) ** 2)\n",
    "\n",
    "    if plot:\n",
    "        cpds_log = cpds.rebin_log(f=f_res)\n",
    "        temp_err = cpds.df*np.power(1.+f_res, range(len(cpds_log.freq)))/2.\n",
    "\n",
    "        plt.figure(figsize=(9,6))\n",
    "        plt.errorbar(cpds_log.freq, cpds_log.power*cpds_log.freq, xerr=temp_err, \\\n",
    "                     yerr=cpds_log.power_err*cpds_log.freq, fmt='none', lw=0.5, color='black')\n",
    "        plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                 np.concatenate([cpds_log.power*cpds_log.freq, [(cpds_log.power*cpds_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "        \n",
    "        plt.plot(cpds.freq,zero_center_Lorentzian(cpds.freq, *popt)*cpds.freq, color='red', lw=1.0)\n",
    "        plt.xscale('log')\n",
    "        plt.ylim((1e-6,3*np.max(cpds_log.power.real*cpds_log.freq)))\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_dir + 'CPDS_nuPnu_continuum_zero_center.pdf')\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(9,6))\n",
    "        plt.errorbar(cpds_log.freq, cpds_log.power, xerr=temp_err, \\\n",
    "                     yerr=cpds_log.power_err, fmt='none', lw=0.5, color='black')\n",
    "        plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                 np.concatenate([cpds_log.power, [cpds_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "        \n",
    "        plt.plot(cpds.freq,zero_center_Lorentzian(cpds.freq, *popt), color='red', lw=1.0)\n",
    "        plt.xscale('log')\n",
    "        plt.ylim((1e-6,3*np.max(cpds_log.power.real)))\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_dir + 'CPDS_Pnu_continuum_zero_center.pdf')\n",
    "        plt.close()\n",
    "    \n",
    "    return popt, pcov, chisq0, chisq\n",
    "\n",
    "\n",
    "\n",
    "def model_continuum_noise(cpds, plot=True, plot_dir='/Users/sean/Desktop/', f_res = 0.5):\n",
    "    n_L = 0\n",
    "    L_args = []\n",
    "    L_bounds = []\n",
    "    chisq0 = np.sum(((cpds.power-np.mean(cpds.power))/ cpds.power_err) ** 2)\n",
    "    chisq = []\n",
    "    popt_list = []\n",
    "    pcov_list = []\n",
    "    del_chisq = -100000\n",
    "    while del_chisq < 0.0:\n",
    "        n_L += 1\n",
    "        if n_L ==1:\n",
    "            L_args = np.array([1.0, 0.1, 10.])\n",
    "            L_bounds = np.array([[[0.0, np.max(cpds.freq)], [0.0, 2.0], [0,np.inf]]])\n",
    "        else:\n",
    "            L_args = np.vstack((L_args, [1.0, 0.1, 10.]))\n",
    "            L_bounds = np.concatenate((L_bounds, [[(0.0, np.max(cpds.freq)), (0.0, 10.0), (0,np.inf)]]))\n",
    "                \n",
    "        temp_p0 = L_args.T.flatten()\n",
    "        temp_bounds = [L_bounds.T.flatten()[:3*n_L], L_bounds.T.flatten()[3*n_L:]]\n",
    "        \n",
    "        popt, pcov = scipy.optimize.curve_fit(N_Lorentzian, cpds.freq, cpds.power, sigma = cpds.power_err, \\\n",
    "                                              p0 = temp_p0, bounds= temp_bounds)\n",
    "        temp_chisq = np.sum(((cpds.power - N_Lorentzian(cpds.freq, *popt)) / cpds.power_err) ** 2)\n",
    "        \n",
    "        if n_L==1:\n",
    "            del_chisq = temp_chisq-chisq0\n",
    "        else:\n",
    "            del_chisq = temp_chisq-chisq[-1]\n",
    "        chisq.append(temp_chisq)\n",
    "        popt_list.append(popt)\n",
    "        pcov_list.append(pcov)\n",
    "        \n",
    "        L_args = np.array([popt[:n_L], popt[n_L:n_L + n_L], popt[n_L+n_L:n_L+n_L+n_L]]).T\n",
    "\n",
    "        if plot:\n",
    "            cpds_log = cpds.rebin_log(f=f_res)\n",
    "            temp_err = cpds.df*np.power(1.+f_res, range(len(cpds_log.freq)))/2.\n",
    "\n",
    "            plt.figure(figsize=(9,6))\n",
    "            plt.errorbar(cpds_log.freq, cpds_log.power*cpds_log.freq, xerr=temp_err, \\\n",
    "                         yerr=cpds_log.power_err*cpds_log.freq, fmt='none', lw=0.5, color='black')\n",
    "            plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                     np.concatenate([cpds_log.power*cpds_log.freq, [(cpds_log.power*cpds_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "            \n",
    "            for i in range(n_L):\n",
    "                plt.plot(cpds.freq, Lorentzian(cpds.freq, *((L_args[i])))*cpds.freq, color='red', ls='dotted', lw=1.0)\n",
    "            plt.plot(cpds.freq,N_Lorentzian(cpds.freq, *popt)*cpds.freq, color='red', lw=1.0)\n",
    "            plt.xscale('log')\n",
    "            plt.ylim((1e-6,3*np.max(cpds_log.power.real*cpds_log.freq)))\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_dir + 'CPDS_nuPnu_continuum_' + str(int(n_L)) + '_comps.pdf')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure(figsize=(9,6))\n",
    "            plt.errorbar(cpds_log.freq, cpds_log.power, xerr=temp_err, \\\n",
    "                         yerr=cpds_log.power_err, fmt='none', lw=0.5, color='black')\n",
    "            plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                     np.concatenate([cpds_log.power, [cpds_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "\n",
    "            for i in range(n_L):\n",
    "                plt.plot(cpds.freq, Lorentzian(cpds.freq, *((L_args[i]))), color='red', ls='dotted', lw=1.0)\n",
    "            plt.plot(cpds.freq,N_Lorentzian(cpds.freq, *popt), color='red', lw=1.0)\n",
    "            plt.xscale('log')\n",
    "            plt.ylim((1e-6,3*np.max(cpds_log.power.real)))\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_dir + 'CPDS_Pnu_continuum_' + str(int(n_L)) + '_comps.pdf')\n",
    "            plt.close()\n",
    "    \n",
    "    return n_L, popt_list, pcov_list, chisq0, chisq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Macbook\n"
     ]
    }
   ],
   "source": [
    "OBSID = '80601502001'\n",
    "\n",
    "if platform=='linux' or platform=='linux2':\n",
    "    print('Working on SRL server')\n",
    "    root_dir = '/disk/lif2/spike/IC_342/'\n",
    "elif platform=='darwin':\n",
    "    print('Working on Macbook')\n",
    "    root_dir = '/Volumes/Samsung_1TB/AstroData/Circinus_ULX5/nustar/nustar_80601502001/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80601502001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Computing the bin time ``dt``. This can take time. If you know the bin time, please specify it at light curve creation\n",
      "WARNING:root:Computing the bin time ``dt``. This can take time. If you know the bin time, please specify it at light curve creation\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/sean/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arange: cannot compute length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4016234c35e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                        nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_bk.lc', buff = buff, buffersize = lc_buff_size), bkg_bin=bkg_bin)\n\u001b[1;32m     25\u001b[0m \u001b[0mcurve_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_lc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurve_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurve_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcurve_10s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurve_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcentroid_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurve_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/stingray/lightcurve.py\u001b[0m in \u001b[0;36mrebin\u001b[0;34m(self, dt_new, f, method)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0mbin_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                     utils.rebin_data(t_temp, c_temp, dt_new,\n\u001b[0;32m--> 875\u001b[0;31m                                      yerr=e_temp, method=method)\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mbin_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/stingray/utils.py\u001b[0m in \u001b[0;36mrebin_data\u001b[0;34m(x, y, dx_new, yerr, method, dx)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0moutputerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtotalerr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arange: cannot compute length"
     ]
    }
   ],
   "source": [
    "plt.ion()\n",
    "bin_time = 1/512\n",
    "split_time = 256\n",
    "buff = False\n",
    "lc_buff_size = 60\n",
    "bkg_bin = 32\n",
    "print(OBSID)\n",
    "\n",
    "### Setup\n",
    "products_dir = root_dir + OBSID + '_products/'\n",
    "plot_dir = root_dir + 'figures/'\n",
    "plt.ion()\n",
    "PI_min = 35     # 3.0 keV\n",
    "# PI_min = 260     # 12.0 keV\n",
    "# PI_max = 960   # 40.0 keV\n",
    "PI_max = 1909   # 78.0 keV\n",
    "\n",
    "events = extract_events(products_dir + 'nu' + OBSID + 'A01_cl_barycorr.evt', \\\n",
    "            products_dir + 'nu' + OBSID + 'B01_cl_barycorr.evt')\n",
    "\n",
    "print(events[0].tstart)\n",
    "print(events[1].tstart)\n",
    "\n",
    "curve_A = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_sr.lc', buff = buff, buffersize = lc_buff_size), \\\n",
    "                       nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_bk.lc', buff = buff, buffersize = lc_buff_size), bkg_bin=bkg_bin)\n",
    "curve_B = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_sr.lc', buff = buff, buffersize = lc_buff_size),\\\n",
    "                       nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_bk.lc', buff = buff, buffersize = lc_buff_size), bkg_bin=bkg_bin)\n",
    "curve_total = sum_lc(curve_A, curve_B)\n",
    "# curve_10s = curve_total.rebin(dt_new=10)\n",
    "\n",
    "centroid_A = curve_A.centroid\n",
    "centroid_B = curve_B.centroid\n",
    "extraction_radius = curve_A.radius\n",
    "#     print(centroid_A)\n",
    "#     print(centroid_B)\n",
    "#     print(extraction_radius)\n",
    "\n",
    "t_start = np.min(curve_total.time)\n",
    "\n",
    "## Plot the lightcurve\n",
    "plt.figure(figsize = (9,6))\n",
    "plt.errorbar(curve_total.time-t_start, curve_total.countrate, xerr=curve_total.dt/2., yerr=curve_total.countrate_err, fmt='none', lw = 0.5)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('NuSTAR count rate')\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'bkg_sub_lightcurve.pdf')\n",
    "plt.close()\n",
    "\n",
    "### Create CPDS\n",
    "curve_A = events[0].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius)\n",
    "curve_B = events[1].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius)\n",
    "\n",
    "averaged_cross = crossspec.AveragedCrossspectrum(curve_A, curve_B, segment_size=split_time, norm = 'frac')\n",
    "\n",
    "### Plot CPDS\n",
    "f_res = 0.1\n",
    "averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "averaged_cross_log_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power*averaged_cross_log.freq, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err*averaged_cross_log.freq, fmt='none', color='black', lw=0.5)\n",
    "plt.step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "         np.concatenate([averaged_cross_log.power*averaged_cross_log.freq, [(averaged_cross_log.power*averaged_cross_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,5*np.max(averaged_cross_log.power*averaged_cross_log.freq)))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(plot_dir + 'CPDS_nuPnu_' + str(int(split_time)) + 's.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err, fmt='none', color='black', lw=0.5)\n",
    "plt.step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "         np.concatenate([averaged_cross_log.power, [averaged_cross_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,5*np.max(averaged_cross_log.power)))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(plot_dir + 'CPDS_Pnu_' + str(int(split_time)) + 's.pdf')\n",
    "plt.close()\n",
    "\n",
    "### Calculate Lomb-Scargle\n",
    "# frequency, power = LombScargle(curve_total.time-t_start, curve_total.countrate, dy=curve_total.countrate_err).autopower()\n",
    "# plt.figure(figsize=(9,6))\n",
    "# plt.plot(frequency, power, rasterized=True)\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel('Frequency (Hz)')\n",
    "# plt.ylabel('Lomb-Scargle Power')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(plot_dir + 'lomb_scargle.pdf')\n",
    "\n",
    "### Fit one zero-centered Lorentzian\n",
    "# popt, pcov, chisq0, chisq = model_continuum_noise_zero_center(averaged_cross, plot=True, plot_dir=plot_dir, f_res=f_res)\n",
    "\n",
    "# del_chisq = chisq - chisq0\n",
    "# print(del_chisq/chisq0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324002\n",
      "7.4231098851414385\n",
      "3.989131539035984\n",
      "9.777979792600545\n",
      "1.8574690318325409\n",
      "80502324004\n",
      "1.968161680871277\n",
      "6.430980406486496\n",
      "2.9271719420746707\n",
      "3.37943981470223\n",
      "80502324006\n",
      "2.1087816949081897\n",
      "2.4262763589956413\n",
      "8.632848109553661\n",
      "3.509628669386416\n",
      "80502324008\n",
      "0.6423837346964079\n",
      "0.07488765569478932\n",
      "26.592674709067342\n",
      "1.093924090704803\n",
      "80502324010\n",
      "0.10319234754084575\n",
      "0.00793209949986902\n",
      "30.358032963860943\n",
      "0.8147788680461053\n",
      "80502324012\n",
      "0.06384622043039354\n",
      "0.011154124406335264\n",
      "30.501233523962934\n",
      "1.8453922864861643\n",
      "80502324014\n",
      "0.02844103128730107\n",
      "0.008165643187988866\n",
      "30.003571091919273\n",
      "2.896020209663599\n",
      "80502324016\n",
      "1.3034185395536202\n",
      "0.663880194147966\n",
      "120.03300946078075\n",
      "21.59464223128655\n"
     ]
    }
   ],
   "source": [
    "# for i, OBSID in enumerate(OBSID_list):\n",
    "#     print(OBSID)\n",
    "#     for j in range(len(noise_params[i])):\n",
    "#         print(noise_params[i][j])\n",
    "#         print(np.sqrt(np.diag(noise_error[i][j])))\n",
    "\n",
    "for i, OBSID in enumerate(OBSID_list):\n",
    "    print(OBSID)\n",
    "#     print(noise_params[i])\n",
    "#     print(np.sqrt(np.diag(noise_error[i])))\n",
    "\n",
    "    gamma = noise_params[i][0]\n",
    "    A = noise_params[i][1]\n",
    "\n",
    "    gamma_err = np.sqrt(np.diag(noise_error[i]))[0]\n",
    "    A_err = np.sqrt(np.diag(noise_error[i]))[1]\n",
    "\n",
    "    rms = np.sqrt(A/2)\n",
    "    rms_err = A_err/(4*np.sqrt(A/2))\n",
    "    \n",
    "    print(gamma)\n",
    "    print(gamma_err)\n",
    "    print(rms*100)\n",
    "    print(rms_err*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMS-Energy relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35. 85.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/anaconda/lib/python3.6/site-packages/stingray/utils.py:118: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "150it [00:08, 18.18it/s]\n",
      "150it [00:07, 20.92it/s]\n",
      "150it [00:07, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85. 160.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:09, 16.30it/s]\n",
      "150it [00:07, 19.96it/s]\n",
      "150it [00:08, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160. 335.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:08, 17.59it/s]\n",
      "150it [00:07, 20.82it/s]\n",
      "150it [00:07, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 335. 1210.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:08, 16.97it/s]\n",
      "150it [00:08, 18.33it/s]\n",
      "150it [00:07, 19.89it/s]\n"
     ]
    }
   ],
   "source": [
    "keV_list = np.array([[3.0, 5.0], [5.0, 8.0], [8.0, 15.0], [15.0, 50.0]])\n",
    "PI_list = eV_to_PI(keV_list*1000)\n",
    "rms_list = []\n",
    "rms_err_list = []\n",
    "uplim_list = []\n",
    "\n",
    "for x in PI_list:\n",
    "    print(x)\n",
    "    rms, rms_err, uplim = get_rms(events, [centroid_A, centroid_B], extraction_radius, PI_min=x[0], PI_max=x[1], nu_min=1e-4, nu_max=1., split_time=split_time, bin_time = bin_time, plot = False)\n",
    "    rms_list.append(rms*100)\n",
    "    rms_err_list.append(rms_err*100)\n",
    "    uplim_list.append(uplim)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(uplim_list)\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.errorbar((keV_list.T[0]+keV_list.T[1])/2, rms_list, xerr = (keV_list.T[0]-keV_list.T[1])/2, yerr = rms_err_list, fmt='none', lw=1.0, uplims=uplim_list)\n",
    "ax.set_xscale('log')\n",
    "# plt.yscale('log')\n",
    "ax.set_ylabel(r'$\\mathrm{rms\\ (\\%)}$')\n",
    "ax.set_xlabel('Energy (keV)')\n",
    "ax.set_xticks([3, 4, 5, 6, 7, 8,9, 20, 30, 40, 50], minor=True)\n",
    "ax.set_xticks([10], minor=False)\n",
    "ax.set_xticklabels(['3','','','','','','','','','','50'], minor=True)\n",
    "ax.set_xticklabels(['10'], minor=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'rms_E.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "593px",
    "left": "889px",
    "right": "20px",
    "top": "315px",
    "width": "315px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
