{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/crossspectrum.py:21: UserWarning: Using standard scipy fft\n",
      "  warnings.warn(\"Using standard scipy fft\")\n",
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/hendrics/io.py:24: UserWarning: Warning! NetCDF is not available. Using pickle format.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "import sys\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import emcee\n",
    "import corner\n",
    "from IPython.display import display, Math\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.modeling import functional_models, fitting\n",
    "from astropy.timeseries import LombScargle\n",
    "\n",
    "import stingray.events as ev\n",
    "import stingray.lightcurve as lc\n",
    "from stingray import io\n",
    "import stingray.powerspectrum as powspec \n",
    "import stingray.crossspectrum as crossspec\n",
    "from hendrics.efsearch import dyn_folding_search, z_n_search, folding_search\n",
    "import stingray.gti as sting_gti\n",
    "import stingray.pulse.pulsar as plsr\n",
    "from stingray import stats\n",
    "\n",
    "\n",
    "sns.set_context('talk')\n",
    "# sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "sys.path.insert(1, '/Users/sean/scripts/helpers')\n",
    "\n",
    "from stingray_plus import *\n",
    "\n",
    "def minimize_remainder(arr, min_div, max_div):\n",
    "    divisors = np.linspace(min_div, max_div, num=100)\n",
    "    remainders = []\n",
    "    for div in divisors:\n",
    "        remainders.append(np.sum(np.mod(arr, div)))\n",
    "        \n",
    "    return divisors[np.argmin(remainders)]\n",
    "\n",
    "def power_law(f, B, gamma):\n",
    "    return B*np.power(f,gamma)\n",
    "\n",
    "def Lorentzian(f, peakf, Q, A):\n",
    "    # gamma = HWHM\n",
    "    # peakf = centroid frequency\n",
    "    gamma = peakf/(2.0 * Q)\n",
    "    return (A * np.square(gamma)/(np.pi*gamma*(np.square(f-peakf) + np.square(gamma))))\n",
    "\n",
    "def zero_center_Lorentzian(f, gamma, A):\n",
    "    # gamma = HWHM\n",
    "    # peakf = centroid frequency\n",
    "    return (A * np.square(gamma)/(np.pi*gamma*(np.square(f) + np.square(gamma))))\n",
    "\n",
    "def Lorentzian_C(f, peakf, Q, A, C):\n",
    "    return Lorentzian(f, peakf, Q, A) + C\n",
    "\n",
    "def Lorentzian_power(f, peakf, Q, A, B, gamma):\n",
    "    return Lorentzian(f, peakf, Q, A) + power_law(f, B, gamma)\n",
    "\n",
    "def N_Lorentzian(f, *args):\n",
    "    N = int(len(args)/3)\n",
    "    peak_nu = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    model = np.zeros(np.shape(f))\n",
    "    for i in range(N):\n",
    "        model = model + Lorentzian(f, peak_nu[i], Qs[i], As[i])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def N_Lorentzian_C(f, *args):\n",
    "    N = int((len(args)-1)/3)\n",
    "    peak_nu = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    C = args[-1]\n",
    "    model = C * np.ones(np.shape(f))\n",
    "    for i in range(N):\n",
    "        model = model + Lorentzian(f, peak_nu[i], Qs[i], As[i])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def N_Lorentzian_power(f, *args):\n",
    "    N = int((len(args)-2)/3)\n",
    "    peak_nu = args[:N]\n",
    "    Qs = args[N:N+N]\n",
    "    As = args[N+N:N+N+N]\n",
    "    B, alpha = args[-2:]\n",
    "    model = power_law(f, B, alpha)\n",
    "    for i in range(N):\n",
    "        gamma = peak_nu[i]/(2.0 * Qs[i])\n",
    "        model = model + (As[i] * np.square(gamma)/(np.pi*gamma*(np.square(f-peak_nu[i]) + np.square(gamma))))\n",
    "        \n",
    "    return model\n",
    "\n",
    "def QPO_scan(cross_spec, f_min=1e-4, f_max=2000., f_bin=1000, n_lorentz = 1):\n",
    "    f_mask = (cross_spec.freq > f_min) * (cross_spec.freq < f_max)\n",
    "    freq_steps = np.logspace(np.log10(cross_spec.freq[f_mask][0]), np.log10(cross_spec.freq[f_mask][-1]), f_bin + 2)\n",
    "    xdata = cross_spec.freq[f_mask]\n",
    "    ydata = cross_spec.power[f_mask]\n",
    "    sigma = cross_spec.power_err[f_mask]\n",
    "    \n",
    "    pl_popt, pl_pcov = scipy.optimize.curve_fit(power_law, xdata, ydata, sigma = sigma, p0 = [10., -1.0], \\\n",
    "                                                bounds=np.array([(0.0, np.inf), (-np.inf, 0.0)]).T)\n",
    "    print(pl_popt)\n",
    "    chisq0 = np.sum(((ydata - power_law(xdata, *pl_popt)) / sigma) ** 2)\n",
    "    chisq = []\n",
    "    for i in tqdm(range(len(freq_steps[1:-1]))):\n",
    "        f = freq_steps[i+1]\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_power, xdata, ydata, sigma = sigma, p0 = [f, 2.0, 0.1, pl_popt[0], pl_popt[1]], \\\n",
    "                                              bounds=np.array([(f - (f-freq_steps[i])/2., f + (freq_steps[i+2] - f)/2.0), (1.0,np.inf), (0.0,np.inf), (0.0, np.inf), (-np.inf, 0.0)]).T)\n",
    "        chisq.append(np.sum(((ydata - Lorentzian_power(xdata, *popt)) / sigma) ** 2))\n",
    "    dof = len(xdata)-len(popt)\n",
    "    return freq_steps[1:-1], chisq0, np.array(chisq), dof\n",
    "\n",
    "\n",
    "\n",
    "def fit_peaks(xdata, ydata, sigma, nu_peak):\n",
    "    \n",
    "    popt_arr = []\n",
    "    pcov_arr = []\n",
    "\n",
    "    for i, p in enumerate(nu_peak):\n",
    "        f_bound = None\n",
    "        if len(nu_peak)==1:\n",
    "            f_bound = (np.min(xdata), np.max(xdata))\n",
    "        else:\n",
    "            if i == 0:\n",
    "                f_bound = (np.min(xdata), p + (nu_peak[i+1] - p)/2)\n",
    "            elif i==len(nu_peak)-1:\n",
    "                f_bound = (p + (nu_peak[i-1] - p)/2, np.max(xdata))\n",
    "            else:\n",
    "                f_bound = (p + (nu_peak[i-1] - p)/2, p + (nu_peak[i+1] - p)/2)\n",
    "\n",
    "        par_bounds = np.array([f_bound, (1.0,np.inf), (0, np.inf), (0, np.inf), (-np.inf, 0.0)]).T\n",
    "        p0 = [p, 5.0, 0.1, 0.02, -0.5]\n",
    "        popt, pcov = scipy.optimize.curve_fit(Lorentzian_power, xdata, ydata, sigma = sigma, p0 = p0, bounds = par_bounds)\n",
    "        popt_arr.append(popt)\n",
    "        pcov_arr.append(pcov)\n",
    "\n",
    "    popt_arr = np.array(popt_arr)\n",
    "    pcov_arr = np.array(pcov_arr)\n",
    "\n",
    "    return popt_arr, pcov_arr\n",
    "\n",
    "def get_rms(events, centroids, radius, PI_min=35, PI_max=1210, nu_min=1e-4, nu_max=100., split_time=512, bin_time = 1/1024, plot = False):\n",
    "    \n",
    "    curve_A = events[0].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroids[0], radius = radius)\n",
    "    curve_B = events[1].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroids[1], radius = radius)\n",
    "    \n",
    "    average_CPDS = crossspec.AveragedCrossspectrum(curve_A, curve_B, segment_size=split_time, norm = 'frac')\n",
    "    \n",
    "    if plot:\n",
    "        f_res = 0.1\n",
    "        plt.figure(figsize=(9,6))\n",
    "        averaged_cross_log = average_CPDS.rebin_log(f=f_res)\n",
    "        averaged_cross_log_err = average_CPDS.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "        plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power*averaged_cross_log.freq, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err*averaged_cross_log.freq, fmt='none', lw=0.5)\n",
    "        plt.xscale('log')\n",
    "        plt.ylim((1e-4,5*np.max(averaged_cross_log.power.real)))\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Leahy Power')\n",
    "        plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "#         plt.savefig(plot_dir + 'averaged_cross_spectrum_' + str(int(split_time)) + 's.pdf')\n",
    "        plt.close()\n",
    "    \n",
    "    rms_square = np.sum(average_CPDS.power[(average_CPDS.freq > nu_min) * (average_CPDS.freq < nu_max)])*average_CPDS.df\n",
    "    rms_square_err = np.sqrt(np.sum(np.square(average_CPDS.power_err[(average_CPDS.freq > nu_min) * (average_CPDS.freq < nu_max)])))*average_CPDS.df\n",
    "    \n",
    "    if rms_square < 0.0:\n",
    "        uplim = True\n",
    "        rms = np.sqrt(rms_square + 2.6*rms_square_err)\n",
    "    else:\n",
    "        uplim = False\n",
    "        rms = np.sqrt(rms_square)\n",
    "        \n",
    "    rms_err = np.sqrt(np.sum(np.square(average_CPDS.power_err[(average_CPDS.freq > nu_min) * (average_CPDS.freq < nu_max)])))*average_CPDS.df/(2*rms)\n",
    "\n",
    "    return rms, rms_err, uplim\n",
    "\n",
    "def model_continuum_noise_zero_center(cpds, plot=True, plot_dir='/Users/sean/Desktop/', f_res = 0.5):\n",
    "\n",
    "    chisq0 = np.sum(((cpds.power-np.mean(cpds.power))/ cpds.power_err) ** 2)\n",
    "\n",
    "    popt, pcov = scipy.optimize.curve_fit(zero_center_Lorentzian, cpds.freq, cpds.power, sigma = cpds.power_err, \\\n",
    "                                          p0 = [0.1, 10.], bounds= [[0.0,0.0], [np.inf, np.inf]])\n",
    "    chisq = np.sum(((cpds.power - zero_center_Lorentzian(cpds.freq, *popt)) / cpds.power_err) ** 2)\n",
    "\n",
    "    if plot:\n",
    "        cpds_log = cpds.rebin_log(f=f_res)\n",
    "        temp_err = cpds.df*np.power(1.+f_res, range(len(cpds_log.freq)))/2.\n",
    "\n",
    "        plt.figure(figsize=(9,6))\n",
    "        plt.errorbar(cpds_log.freq, cpds_log.power*cpds_log.freq, xerr=temp_err, \\\n",
    "                     yerr=cpds_log.power_err*cpds_log.freq, fmt='none', lw=0.5, color='black')\n",
    "        plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                 np.concatenate([cpds_log.power*cpds_log.freq, [(cpds_log.power*cpds_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "        \n",
    "        plt.plot(cpds.freq,zero_center_Lorentzian(cpds.freq, *popt)*cpds.freq, color='red', lw=1.0)\n",
    "        plt.xscale('log')\n",
    "        plt.ylim((1e-6,3*np.max(cpds_log.power.real*cpds_log.freq)))\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_dir + 'CPDS_nuPnu_continuum_zero_center.pdf')\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(9,6))\n",
    "        plt.errorbar(cpds_log.freq, cpds_log.power, xerr=temp_err, \\\n",
    "                     yerr=cpds_log.power_err, fmt='none', lw=0.5, color='black')\n",
    "        plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                 np.concatenate([cpds_log.power, [cpds_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "        \n",
    "        plt.plot(cpds.freq,zero_center_Lorentzian(cpds.freq, *popt), color='red', lw=1.0)\n",
    "        plt.xscale('log')\n",
    "        plt.ylim((1e-6,3*np.max(cpds_log.power.real)))\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_dir + 'CPDS_Pnu_continuum_zero_center.pdf')\n",
    "        plt.close()\n",
    "    \n",
    "    return popt, pcov, chisq0, chisq\n",
    "\n",
    "\n",
    "\n",
    "def model_continuum_noise(cpds, plot=True, plot_dir='/Users/sean/Desktop/', f_res = 0.5):\n",
    "    n_L = 0\n",
    "    L_args = []\n",
    "    L_bounds = []\n",
    "    chisq0 = np.sum(((cpds.power-np.mean(cpds.power))/ cpds.power_err) ** 2)\n",
    "    chisq = []\n",
    "    popt_list = []\n",
    "    pcov_list = []\n",
    "    del_chisq = -100000\n",
    "    while del_chisq < 0.0:\n",
    "        n_L += 1\n",
    "        if n_L ==1:\n",
    "            L_args = np.array([1.0, 0.1, 10.])\n",
    "            L_bounds = np.array([[[0.0, np.max(cpds.freq)], [0.0, 2.0], [0,np.inf]]])\n",
    "        else:\n",
    "            L_args = np.vstack((L_args, [1.0, 0.1, 10.]))\n",
    "            L_bounds = np.concatenate((L_bounds, [[(0.0, np.max(cpds.freq)), (0.0, 10.0), (0,np.inf)]]))\n",
    "                \n",
    "        temp_p0 = L_args.T.flatten()\n",
    "        temp_bounds = [L_bounds.T.flatten()[:3*n_L], L_bounds.T.flatten()[3*n_L:]]\n",
    "        \n",
    "        popt, pcov = scipy.optimize.curve_fit(N_Lorentzian, cpds.freq, cpds.power, sigma = cpds.power_err, \\\n",
    "                                              p0 = temp_p0, bounds= temp_bounds)\n",
    "        temp_chisq = np.sum(((cpds.power - N_Lorentzian(cpds.freq, *popt)) / cpds.power_err) ** 2)\n",
    "        \n",
    "        if n_L==1:\n",
    "            del_chisq = temp_chisq-chisq0\n",
    "        else:\n",
    "            del_chisq = temp_chisq-chisq[-1]\n",
    "        chisq.append(temp_chisq)\n",
    "        popt_list.append(popt)\n",
    "        pcov_list.append(pcov)\n",
    "        \n",
    "        L_args = np.array([popt[:n_L], popt[n_L:n_L + n_L], popt[n_L+n_L:n_L+n_L+n_L]]).T\n",
    "\n",
    "        if plot:\n",
    "            cpds_log = cpds.rebin_log(f=f_res)\n",
    "            temp_err = cpds.df*np.power(1.+f_res, range(len(cpds_log.freq)))/2.\n",
    "\n",
    "            plt.figure(figsize=(9,6))\n",
    "            plt.errorbar(cpds_log.freq, cpds_log.power*cpds_log.freq, xerr=temp_err, \\\n",
    "                         yerr=cpds_log.power_err*cpds_log.freq, fmt='none', lw=0.5, color='black')\n",
    "            plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                     np.concatenate([cpds_log.power*cpds_log.freq, [(cpds_log.power*cpds_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "            \n",
    "            for i in range(n_L):\n",
    "                plt.plot(cpds.freq, Lorentzian(cpds.freq, *((L_args[i])))*cpds.freq, color='red', ls='dotted', lw=1.0)\n",
    "            plt.plot(cpds.freq,N_Lorentzian(cpds.freq, *popt)*cpds.freq, color='red', lw=1.0)\n",
    "            plt.xscale('log')\n",
    "            plt.ylim((1e-6,3*np.max(cpds_log.power.real*cpds_log.freq)))\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_dir + 'CPDS_nuPnu_continuum_' + str(int(n_L)) + '_comps.pdf')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure(figsize=(9,6))\n",
    "            plt.errorbar(cpds_log.freq, cpds_log.power, xerr=temp_err, \\\n",
    "                         yerr=cpds_log.power_err, fmt='none', lw=0.5, color='black')\n",
    "            plt.step(np.concatenate([cpds_log.freq-temp_err, [cpds_log.freq[-1]+temp_err[-1]]]), \\\n",
    "                     np.concatenate([cpds_log.power, [cpds_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "\n",
    "            for i in range(n_L):\n",
    "                plt.plot(cpds.freq, Lorentzian(cpds.freq, *((L_args[i]))), color='red', ls='dotted', lw=1.0)\n",
    "            plt.plot(cpds.freq,N_Lorentzian(cpds.freq, *popt), color='red', lw=1.0)\n",
    "            plt.xscale('log')\n",
    "            plt.ylim((1e-6,3*np.max(cpds_log.power.real)))\n",
    "            plt.yscale('log')\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(plot_dir + 'CPDS_Pnu_continuum_' + str(int(n_L)) + '_comps.pdf')\n",
    "            plt.close()\n",
    "    \n",
    "    return n_L, popt_list, pcov_list, chisq0, chisq\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Macbook\n"
     ]
    }
   ],
   "source": [
    "# OBSID_list = [str(80502324000 + int(2*(i+1))) for i in range(8)]\n",
    "# print(OBSID_list)\n",
    "\n",
    "OBSID_list = ['80502324008', '80502324010', '80502324012', '80502324014']\n",
    "\n",
    "if platform=='linux' or platform=='linux2':\n",
    "    print('Working on SRL server')\n",
    "    root_dir = '/disk/lif2/spike/MAXI_J0637-430/'\n",
    "elif platform=='darwin':\n",
    "    print('Working on Macbook')\n",
    "    root_dir = '/Volumes/Samsung_1TB/AstroData/MAXI_J0637-430/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "179it [00:09, 19.29it/s]\n",
      "179it [00:09, 19.67it/s]\n",
      "179it [00:09, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "438it [00:25, 17.00it/s]\n",
      "438it [00:23, 18.28it/s]\n",
      "438it [00:23, 18.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "188it [00:11, 16.32it/s]\n",
      "188it [00:09, 19.90it/s]\n",
      "188it [00:11, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "246it [00:12, 19.97it/s]\n",
      "246it [00:14, 16.88it/s]\n",
      "246it [00:15, 15.81it/s]\n"
     ]
    }
   ],
   "source": [
    "cpds_list = []\n",
    "plt.ion()\n",
    "bin_time = 1/512\n",
    "split_time = 256\n",
    "buff = False\n",
    "lc_buff_size = 60\n",
    "bkg_bin = 32\n",
    "noise_params = []\n",
    "noise_error = []\n",
    "# cnt_rate = []\n",
    "# cnt_rate_err = []\n",
    "# softness_ratio = []\n",
    "# softness_ratio_err = []\n",
    "for OBSID in OBSID_list:\n",
    "    print(OBSID)\n",
    "    \n",
    "    ### Setup\n",
    "    products_dir = root_dir + OBSID + '_products/'\n",
    "    plot_dir = root_dir + 'figures/' + OBSID + '/'\n",
    "    plt.ion()\n",
    "    PI_min = 35     # 3.0 keV\n",
    "    # PI_min = 260     # 12.0 keV\n",
    "    # PI_max = 960   # 40.0 keV\n",
    "    PI_max = 1909   # 78.0 keV\n",
    "    \n",
    "    events = extract_events(products_dir + 'nu' + OBSID + 'A01_cl_barycorr.evt', \\\n",
    "                products_dir + 'nu' + OBSID + 'B01_cl_barycorr.evt')\n",
    "    \n",
    "    bkg_curve_A = nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_bk.lc', buff = buff, buffersize = lc_buff_size)\n",
    "    bkg_curve_B = nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_bk.lc', buff = buff, buffersize = lc_buff_size)\n",
    "#     \n",
    "#     bkg_curve_total = sum_lc(bkg_curve_A, bkg_curve_B)\n",
    "    \n",
    "    curve_A = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_sr.lc', buff = buff, buffersize = lc_buff_size), \\\n",
    "                           bkg_curve_A, bkg_bin=bkg_bin)\n",
    "    curve_B = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_sr.lc', buff = buff, buffersize = lc_buff_size),\\\n",
    "                           bkg_curve_B, bkg_bin=bkg_bin)\n",
    "    curve_total = sum_lc(curve_A, curve_B)\n",
    "#     curve_10s = curve_total.rebin(dt_new=10)\n",
    "\n",
    "    centroid_A = curve_A.centroid\n",
    "    centroid_B = curve_B.centroid\n",
    "    extraction_radius = curve_A.radius\n",
    "    area_ratio = np.square(curve_A.radius/bkg_curve_A.radius)\n",
    "    \n",
    "    bkg_rate = bkg_curve_A.meanrate\n",
    "    src_rate = curve_A.meanrate\n",
    "\n",
    "\n",
    "#     print(centroid_A)\n",
    "#     print(centroid_B)\n",
    "#     print(extraction_radius)\n",
    "#     cnt_rate.append(np.mean(curve_total.countrate))\n",
    "#     cnt_rate_err.append(np.std(curve_total.countrate))\n",
    "    \n",
    "\n",
    "    t_start = np.min(curve_total.time)\n",
    "\n",
    "    ### Plot the lightcurve\n",
    "#     plt.figure(figsize = (9,6))\n",
    "#     plt.errorbar(curve_10s.time-t_start, curve_10s.countrate, xerr=curve_10s.dt/2., yerr=curve_10s.countrate_err, fmt='none', lw = 0.5)\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('NuSTAR count rate')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(plot_dir + 'bkg_sub_lightcurve.pdf')\n",
    "#     plt.close()\n",
    "    \n",
    "    ### Create CPDS\n",
    "    curve_A = events[0].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius)\n",
    "    curve_B = events[1].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius)\n",
    "    \n",
    "# #     curve_A_soft = events[0].to_lc(dt = 1, pi_low=35, pi_high=110, centroid = centroid_A, radius = extraction_radius)\n",
    "# #     curve_B_soft = events[1].to_lc(dt = 1, pi_low=35, pi_high=110, centroid = centroid_B, radius = extraction_radius)\n",
    "# #     curve_A_hard = events[0].to_lc(dt = 1, pi_low=110, pi_high=260, centroid = centroid_A, radius = extraction_radius)\n",
    "# #     curve_B_hard = events[1].to_lc(dt = 1, pi_low=110, pi_high=260, centroid = centroid_B, radius = extraction_radius)\n",
    "    \n",
    "#     soft_counts = np.sum((np.sqrt(np.square(events[0].x-centroid_A[0]) + np.square(events[0].y-centroid_A[1])) <= extraction_radius) * (events[0].pi >= 35) * (events[0].pi < 110)) + \\\n",
    "#                   np.sum((np.sqrt(np.square(events[1].x-centroid_B[0]) + np.square(events[1].y-centroid_B[1])) <= extraction_radius) * (events[1].pi >= 35) * (events[1].pi < 110))\n",
    "#     hard_counts = np.sum((np.sqrt(np.square(events[0].x-centroid_A[0]) + np.square(events[0].y-centroid_A[1])) <= extraction_radius) * (events[0].pi >= 110) * (events[0].pi < 260)) + \\\n",
    "#                   np.sum((np.sqrt(np.square(events[1].x-centroid_B[0]) + np.square(events[1].y-centroid_B[1])) <= extraction_radius) * (events[1].pi >= 110) * (events[1].pi < 260))\n",
    "    \n",
    "#     softness_ratio.append(soft_counts/hard_counts)\n",
    "#     softness_ratio_err.append(np.sqrt(soft_counts + (np.square(soft_counts)/hard_counts))/hard_counts)\n",
    "\n",
    "    averaged_cross = crossspec.AveragedCrossspectrum(curve_A, curve_B, segment_size=split_time, norm = 'frac')\n",
    "    averaged_cross.power = averaged_cross.power * np.square((1/(1-0.0025*(curve_A.meanrate))) * ((src_rate + (bkg_rate*area_ratio))/(src_rate)))\n",
    "    averaged_cross.power_err = averaged_cross.power_err * np.square((1/(1-0.0025*(curve_A.meanrate))) * ((src_rate + (bkg_rate*area_ratio))/(src_rate)))\n",
    "\n",
    "    \n",
    "    cpds_list.append(averaged_cross)\n",
    "\n",
    "    ### Plot CPDS\n",
    "    f_res = 0.1\n",
    "    averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "    averaged_cross_log_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power*averaged_cross_log.freq, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err*averaged_cross_log.freq, fmt='none', color='black', lw=0.5)\n",
    "    plt.step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "             np.concatenate([averaged_cross_log.power*averaged_cross_log.freq, [(averaged_cross_log.power*averaged_cross_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "    plt.xscale('log')\n",
    "    plt.ylim((1e-4,10))\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel(r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(plot_dir + 'CPDS_nuPnu_' + str(int(split_time)) + 's.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.errorbar(averaged_cross_log.freq, averaged_cross_log.power, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err, fmt='none', color='black', lw=0.5)\n",
    "    plt.step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "             np.concatenate([averaged_cross_log.power, [averaged_cross_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "    plt.xscale('log')\n",
    "    plt.ylim((1e-4,10))\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(plot_dir + 'CPDS_Pnu_' + str(int(split_time)) + 's.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2,  gridspec_kw = {'width_ratios':[1, 1]}, figsize=(20, 6))\n",
    "    \n",
    "#     ax1.errorbar(averaged_cross_log.freq, averaged_cross_log.power, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err, fmt='none', color='black', lw=0.5)\n",
    "#     ax1.step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "#              np.concatenate([averaged_cross_log.power, [averaged_cross_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "#     ax1.set_xscale('log')\n",
    "#     ax1.set_ylim((1e-4,10))\n",
    "#     ax1.set_yscale('log')\n",
    "#     ax1.set_xlabel('Frequency (Hz)')\n",
    "#     ax1.set_ylabel(r'$\\mathrm{Power\\ (rms/mean)^{2}/Hz}$')\n",
    "\n",
    "#     ax2.errorbar(curve_10s.time-t_start, curve_10s.countrate, xerr=curve_10s.dt/2., yerr=curve_10s.countrate_err, fmt='none', lw = 0.5)\n",
    "#     ax2.set_xlabel('Time (s)')\n",
    "#     ax2.set_ylabel('NuSTAR count rate')\n",
    "#     ax2.set_ylim((0,60))\n",
    "#     plt.tight_layout()\n",
    "#     # plt.show()\n",
    "#     plt.savefig(plot_dir + 'CPDS_Pnu_' + str(int(split_time)) + 's_4gif.pdf')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "#     ## Calculate Lomb-Scargle\n",
    "#     frequency, power = LombScargle(curve_total.time-t_start, curve_total.countrate, dy=curve_total.countrate_err).autopower()\n",
    "#     plt.figure(figsize=(9,6))\n",
    "#     plt.plot(frequency, power, rasterized=True)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('Lomb-Scargle Power')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(plot_dir + 'lomb_scargle.pdf')\n",
    "\n",
    "#     ## Calculate Lomb-Scargle\n",
    "#     frequency, power = LombScargle(curve_total.time-t_start, np.ones(np.shape(curve_total.countrate)), fit_mean=False, center_data=False).autopower()\n",
    "#     plt.figure(figsize=(9,6))\n",
    "#     plt.plot(frequency, power, rasterized=True)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('Lomb-Scargle Power')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(plot_dir + 'lomb_scargle_window.pdf')\n",
    "\n",
    "#     ## Calculate bkg Lomb-Scargle\n",
    "#     frequency, power = LombScargle(bkg_curve_total.time-t_start, bkg_curve_total.countrate, dy=bkg_curve_total.countrate_err).autopower()\n",
    "#     plt.figure(figsize=(9,6))\n",
    "#     plt.plot(frequency, power, rasterized=True)\n",
    "#     plt.xscale('log')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('Lomb-Scargle Power')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(plot_dir + 'lomb_scargle_bkg.pdf')\n",
    "\n",
    "    \n",
    "#     ## Fit several Lorentzians\n",
    "#     n_L, popt_list, pcov_list, chisq0, chisq = model_continuum_noise(averaged_cross, plot=True, plot_dir=plot_dir, f_res=f_res)\n",
    "\n",
    "#     del_chisq = np.array(chisq) - chisq0\n",
    "\n",
    "#     plt.figure(figsize=(9,6))\n",
    "#     plt.plot(np.array(range(n_L)) + 1, -del_chisq)\n",
    "#     plt.xlabel('N_Lorentzians')\n",
    "#     plt.ylabel(r'$\\Delta\\chi^{2}$')\n",
    "#     # plt.yscale('log')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(plot_dir + 'fit_chisq.pdf')\n",
    "#     plt.close()\n",
    "\n",
    "    \n",
    "    ### Fit one zero-centered Lorentzian\n",
    "    popt, pcov, chisq0, chisq = model_continuum_noise_zero_center(averaged_cross, plot=True, plot_dir=plot_dir, f_res=f_res)\n",
    "\n",
    "#     del_chisq = chisq - chisq0\n",
    "#     print(del_chisq/chisq0)\n",
    "    \n",
    "    noise_params.append(popt)\n",
    "    noise_error.append(pcov)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "179it [00:09, 19.30it/s]\n",
      "179it [00:09, 18.93it/s]\n",
      "179it [00:08, 20.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "438it [00:20, 21.12it/s]\n",
      "438it [00:20, 21.10it/s]\n",
      "438it [00:20, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "188it [00:11, 16.58it/s]\n",
      "188it [00:10, 18.64it/s]\n",
      "188it [00:10, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/opt/anaconda3/lib/python3.8/site-packages/stingray/utils.py:119: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "246it [00:12, 20.11it/s]\n",
      "246it [00:12, 20.45it/s]\n",
      "246it [00:12, 19.63it/s]\n"
     ]
    }
   ],
   "source": [
    "plt.ion()\n",
    "plot_dir = root_dir + 'figures/'\n",
    "bin_time = 1/512\n",
    "split_time = 256\n",
    "buff = False\n",
    "lc_buff_size = 60\n",
    "bkg_bin = 32\n",
    "fig, axes = plt.subplots(2, 2, gridspec_kw = {'height_ratios':[1,1], 'width_ratios': [1,1], 'hspace':0, 'wspace':0}, figsize=(12,9), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "# fig, axes = plt.subplots(len(OBSID_list), 1, gridspec_kw = {'height_ratios':[1 for i in range(len(OBSID_list))], 'hspace':0}, figsize=(9,3*len(OBSID_list)), sharex=True)\n",
    "for i, OBSID in enumerate(OBSID_list):\n",
    "    print(OBSID)\n",
    "    \n",
    "    ### Setup\n",
    "    products_dir = root_dir + OBSID + '_products/'\n",
    "    PI_min = 35     # 3.0 keV\n",
    "    # PI_min = 260     # 12.0 keV\n",
    "    # PI_max = 960   # 40.0 keV\n",
    "    PI_max = 1909   # 78.0 keV\n",
    "    \n",
    "    events = extract_events(products_dir + 'nu' + OBSID + 'A01_cl_barycorr.evt', \\\n",
    "                products_dir + 'nu' + OBSID + 'B01_cl_barycorr.evt')\n",
    "    \n",
    "    bkg_curve_A = nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_bk.lc', buff = buff, buffersize = lc_buff_size)\n",
    "    bkg_curve_B = nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_bk.lc', buff = buff, buffersize = lc_buff_size)\n",
    "#     \n",
    "#     bkg_curve_total = sum_lc(bkg_curve_A, bkg_curve_B)\n",
    "    \n",
    "    curve_A = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'A01_sr.lc', buff = buff, buffersize = lc_buff_size), \\\n",
    "                           bkg_curve_A, bkg_bin=bkg_bin)\n",
    "    curve_B = bkg_subtract(nuproducts_to_stingray_lc(products_dir + 'nu' + OBSID + 'B01_sr.lc', buff = buff, buffersize = lc_buff_size),\\\n",
    "                           bkg_curve_B, bkg_bin=bkg_bin)\n",
    "    curve_total = sum_lc(curve_A, curve_B)\n",
    "#     curve_10s = curve_total.rebin(dt_new=10)\n",
    "\n",
    "    centroid_A = curve_A.centroid\n",
    "    centroid_B = curve_B.centroid\n",
    "    extraction_radius = curve_A.radius\n",
    "    \n",
    "    bkg_rate = bkg_curve_A.meanrate\n",
    "    src_rate = curve_A.meanrate\n",
    "    \n",
    "    area_ratio = np.square(curve_A.radius/bkg_curve_A.radius)\n",
    "#     print(centroid_A)\n",
    "#     print(centroid_B)\n",
    "#     print(extraction_radius)\n",
    "#     cnt_rate.append(np.mean(curve_total.countrate))\n",
    "#     cnt_rate_err.append(np.std(curve_total.countrate))\n",
    "    \n",
    "\n",
    "    t_start = np.min(curve_total.time)\n",
    "\n",
    "    ### Create CPDS\n",
    "    curve_A = events[0].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroid_A, radius = extraction_radius)\n",
    "    curve_B = events[1].to_lc(dt = bin_time, pi_low=PI_min, pi_high=PI_max, centroid = centroid_B, radius = extraction_radius)\n",
    "    \n",
    "    averaged_cross = crossspec.AveragedCrossspectrum(curve_A, curve_B, segment_size=split_time, norm = 'frac')\n",
    "    averaged_cross.power = averaged_cross.power * np.square((1/(1-0.0025*(curve_A.meanrate))) * ((src_rate + (bkg_rate*area_ratio))/(src_rate)))\n",
    "    averaged_cross.power_err = averaged_cross.power_err * np.square((1/(1-0.0025*(curve_A.meanrate))) * ((src_rate + (bkg_rate*area_ratio))/(src_rate)))\n",
    "    \n",
    "    ### Plot CPDS\n",
    "    f_res = 0.1\n",
    "    averaged_cross_log = averaged_cross.rebin_log(f=f_res)\n",
    "    averaged_cross_log_err = averaged_cross.df*np.power(1.+f_res, range(len(averaged_cross_log.freq)))/2.\n",
    "    ### Fit one zero-centered Lorentzian\n",
    "    popt, pcov, chisq0, chisq = model_continuum_noise_zero_center(averaged_cross, plot=False)\n",
    "\n",
    "\n",
    "\n",
    "#     axes[i].errorbar(averaged_cross_log.freq, averaged_cross_log.power*averaged_cross_log.freq, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err*averaged_cross_log.freq, fmt='none', color='black', lw=0.5)\n",
    "#     axes[i].step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "#              np.concatenate([averaged_cross_log.power*averaged_cross_log.freq, [(averaged_cross_log.power*averaged_cross_log.freq)[-1]]]), where='post', color='black', lw=0.5)\n",
    "#     axes[i].plot(averaged_cross_log.freq, zero_center_Lorentzian(averaged_cross_log.freq, *popt)*averaged_cross_log.freq, color='red', lw=1.0)\n",
    "#     axes[i].set_xscale('log')\n",
    "#     axes[i].set_ylim((1e-4,10))\n",
    "#     axes[i].set_yscale('log')\n",
    "\n",
    "    axes[i].errorbar(averaged_cross_log.freq, averaged_cross_log.power, xerr=averaged_cross_log_err, yerr=averaged_cross_log.power_err, fmt='none', color='black', lw=0.5)\n",
    "    axes[i].step(np.concatenate([averaged_cross_log.freq-averaged_cross_log_err, [averaged_cross_log.freq[-1]+averaged_cross_log_err[-1]]]), \\\n",
    "             np.concatenate([averaged_cross_log.power, [averaged_cross_log.power[-1]]]), where='post', color='black', lw=0.5)\n",
    "    axes[i].plot(averaged_cross_log.freq, zero_center_Lorentzian(averaged_cross_log.freq, *popt), color='red', lw=1.0)\n",
    "    axes[i].set_xscale('log')\n",
    "    axes[i].set_xlim(1.1e-3,10)\n",
    "    axes[i].set_ylim((2e-4,10))\n",
    "    axes[i].set_yscale('log')\n",
    "    axes[i].tick_params(axis='both',which='both', direction='in', bottom=True, top=True, left=True, right=True)\n",
    "    axes[i].text(2e-1,1, OBSID)\n",
    "\n",
    "# axes[-1].set_xlabel('Frequency (Hz)')\n",
    "# fig.text(0.02, 0.5, r'$\\mathrm{\\nu P_{\\nu}\\ (rms/mean)^{2}}$', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.03, 0.5, r'$\\mathrm{P_{\\nu}\\ (rms/mean)^{2}/Hz}$', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.03, 'Frequency (Hz)', ha='center', va='center', rotation='horizontal')\n",
    "# plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'CPDS_Pnu_' + str(int(split_time)) + 's_2x2panel.pdf')\n",
    "# plt.savefig(plot_dir + 'CPDS_Pnu_' + str(int(split_time)) + 's_4panel.pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80502324008\n",
      "0.6423934514312533\n",
      "0.07488879024408482\n",
      "26.956151039975794\n",
      "1.1088762204150802\n",
      "80502324010\n",
      "0.10319106386323645\n",
      "0.007932000866518385\n",
      "31.11380743291693\n",
      "0.8350629598886821\n",
      "80502324012\n",
      "0.06386755826066375\n",
      "0.011157848069751116\n",
      "31.757466566978\n",
      "1.9214105688574192\n",
      "80502324014\n",
      "0.02853591188465425\n",
      "0.008188798923152975\n",
      "33.36458146516527\n",
      "3.219448716090985\n"
     ]
    }
   ],
   "source": [
    "# for i, OBSID in enumerate(OBSID_list):\n",
    "#     print(OBSID)\n",
    "#     for j in range(len(noise_params[i])):\n",
    "#         print(noise_params[i][j])\n",
    "#         print(np.sqrt(np.diag(noise_error[i][j])))\n",
    "plot_dir = root_dir + 'figures/'\n",
    "# print(noise_params)\n",
    "gamma_list = []\n",
    "gamma_err_list = []\n",
    "rms_list = []\n",
    "rms_err_list =[]\n",
    "for i, OBSID in enumerate(OBSID_list):\n",
    "    print(OBSID)\n",
    "#     print(noise_params[i])\n",
    "#     print(np.sqrt(np.diag(noise_error[i])))\n",
    "\n",
    "    gamma = noise_params[i][0]\n",
    "    A = noise_params[i][1]\n",
    "\n",
    "    gamma_err = np.sqrt(np.diag(noise_error[i]))[0]\n",
    "    A_err = np.sqrt(np.diag(noise_error[i]))[1]\n",
    "\n",
    "    rms = np.sqrt(A/2)\n",
    "    rms_err = A_err/(4*np.sqrt(A/2))\n",
    "    \n",
    "    print(gamma)\n",
    "    print(gamma_err)\n",
    "    print(rms*100)\n",
    "    print(rms_err*100)\n",
    "    \n",
    "    gamma_list.append(gamma)\n",
    "    gamma_err_list.append(gamma_err)\n",
    "    rms_list.append(rms)\n",
    "    rms_err_list.append(rms_err)\n",
    "    \n",
    "# plt.figure(figsize = (9,6))\n",
    "# plt.errorbar(cnt_rate[3:7], gamma_list[3:7], xerr=cnt_rate_err[3:7], yerr=gamma_err_list[3:7], fmt='none', lw = 0.5)\n",
    "# plt.xlabel('NuSTAR count rate')\n",
    "# plt.ylabel('HWHM')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(plot_dir + 'countrate_gamma.pdf')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (9,6))\n",
    "# plt.errorbar(cnt_rate[3:7], rms_list[3:7], xerr=cnt_rate_err[3:7], yerr=rms_err_list[3:7], fmt='none', lw = 0.5)\n",
    "# plt.xlabel('NuSTAR count rate')\n",
    "# plt.ylabel('RMS (%)')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(plot_dir + 'countrate_rms.pdf')\n",
    "# plt.close()\n",
    "\n",
    "# plt.figure(figsize = (9,6))\n",
    "# plt.errorbar(softness_ratio[3:7], gamma_list[3:7], xerr=softness_ratio_err[3:7], yerr=gamma_err_list[3:7], fmt='none', lw = 0.5)\n",
    "# plt.xlabel('Softness Ratio')\n",
    "# plt.ylabel('HWHM')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(plot_dir + 'ratio_gamma.pdf')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMS-Energy relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35. 85.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/anaconda/lib/python3.6/site-packages/stingray/utils.py:118: UserWarning: SIMON says: Errorbars on cross spectra are not thoroughly tested. Please report any inconsistencies.\n",
      "  warnings.warn(\"SIMON says: {0}\".format(message), **kwargs)\n",
      "150it [00:08, 18.18it/s]\n",
      "150it [00:07, 20.92it/s]\n",
      "150it [00:07, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85. 160.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:09, 16.30it/s]\n",
      "150it [00:07, 19.96it/s]\n",
      "150it [00:08, 18.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160. 335.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:08, 17.59it/s]\n",
      "150it [00:07, 20.82it/s]\n",
      "150it [00:07, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 335. 1210.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [00:08, 16.97it/s]\n",
      "150it [00:08, 18.33it/s]\n",
      "150it [00:07, 19.89it/s]\n"
     ]
    }
   ],
   "source": [
    "keV_list = np.array([[3.0, 5.0], [5.0, 8.0], [8.0, 15.0], [15.0, 50.0]])\n",
    "PI_list = eV_to_PI(keV_list*1000)\n",
    "rms_list = []\n",
    "rms_err_list = []\n",
    "uplim_list = []\n",
    "\n",
    "for x in PI_list:\n",
    "    print(x)\n",
    "    rms, rms_err, uplim = get_rms(events, [centroid_A, centroid_B], extraction_radius, PI_min=x[0], PI_max=x[1], nu_min=1e-4, nu_max=1., split_time=split_time, bin_time = bin_time, plot = False)\n",
    "    rms_list.append(rms*100)\n",
    "    rms_err_list.append(rms_err*100)\n",
    "    uplim_list.append(uplim)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(uplim_list)\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.errorbar((keV_list.T[0]+keV_list.T[1])/2, rms_list, xerr = (keV_list.T[0]-keV_list.T[1])/2, yerr = rms_err_list, fmt='none', lw=1.0, uplims=uplim_list)\n",
    "ax.set_xscale('log')\n",
    "# plt.yscale('log')\n",
    "ax.set_ylabel(r'$\\mathrm{rms\\ (\\%)}$')\n",
    "ax.set_xlabel('Energy (keV)')\n",
    "ax.set_xticks([3, 4, 5, 6, 7, 8,9, 20, 30, 40, 50], minor=True)\n",
    "ax.set_xticks([10], minor=False)\n",
    "ax.set_xticklabels(['3','','','','','','','','','','50'], minor=True)\n",
    "ax.set_xticklabels(['10'], minor=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_dir + 'rms_E.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "593px",
    "left": "889px",
    "right": "20px",
    "top": "315px",
    "width": "315px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
